---
title: "R for Non-Programmers: A Guide for Social Scientists"
author: "Daniel Dauber"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "This books is intended for Social Scientists. No matter whether you have years of experiences, this book might come in handy if you never use R or any other programming language before."
---

# Welcome üëã {#welcome .unnumbered}

Placeholder



<!--chapter:end:index.Rmd-->

# Acknowledgments üôè {#acknowledgments .unnumbered}

Special thanks are due to my wife, who supported me in so many ways to get this book completed. Also, I would like to thank my son, who patiently watched me sitting at the computer type this book up.

<!--chapter:end:00_acknowledgements.Rmd-->

# `Readme.` Before you get started {#readme-before-you-get-started}

## A starting point and reference book {#a-starting-point-and-reference-book}

`to be added`

## Download the companion R package {#download-the-companion-r-package}

`to be added`

-   Explain where to download

-   Explain how examples are shown in this book (code in the first grey box, console results in the second grey box

## A 'tidyverse' approach with some basic R {#a-tidyverse-approach-with-some-basic-r}

`to be added`

<!--chapter:end:01_before_you_get_started.Rmd-->


# Why learn a programming language as a non-programmer? {#why-learn-a-programming-language-as-a-non-programmer}

Placeholder


## Learning new tools to analyse your data is always essential {#learning-new-tools-to-analyse-your-data-is-always-essential}
## Programming languages enhance your conceptual thinking {#programming-languages-enhance-your-conceptual-thinking}
## Programming languages allow you to look at your data from a different angle {#programming-languages-allow-you-to-look-at-your-data-from-a-different-angle}
## Learning any programming language will help you learn other programming languages. {#learning-any-programming-language-will-help-you-learn-other-programming-languages.}

<!--chapter:end:02_why_start_learning_a_programming_language.Rmd-->


# Setting up R and RStudio {#setting-up-r-and-rstudio}

Placeholder


## Installing R {#installing-r}
## Installing RStudio {#installing-rstudio}
## When you first start RStudio {#when-you-first-start-rstudio}
## Updating R and RStudio: Living at the pulse of innovation {#updating-r-and-rstudio}
## RStudio Cloud {#rstudio-cloud}

<!--chapter:end:03_setting_up_r_rstudio.Rmd-->


# The RStudio Interface {#the-rstudio-interface}

Placeholder


## The Console window {#the-console-window}
## The Source window {#the-source-window}
## The Environment / History / Connections / Tutorial window {#the-environment-history-connections-tutorial-window}
## The Files / Plots / Packages / Help / Viewer window {#the-files-plots-packages-help-viewer-window}
## Customise your user interface {#customise-your-user-interface}

<!--chapter:end:04_rstudio_interface.Rmd-->


# R Basics: The very fundamentals {#r-basics-the-very-fundamentals}

Placeholder


## Basic computations in R {#basic-computations-in-r}
## Assigning values to objects: '\<-' {#assigning-values-to-objects}
## Functions {#functions}
## R packages {#r-packages}
### Installing packages using `install.packages()` {#installing-packages-using-a-function}
### Installing packages via RStudio's package pane {#installing-packages-via-rstudio}
### Using R Packages {#using-r-packages}
## Coding etiquette {#coding-etiquette}
## Exercises {#exercises-chapter-5}

<!--chapter:end:05_r_basics.Rmd-->


# Starting your R projects {#starting-your-r-projects}

Placeholder


## Creating an R Project file {#creating-an-r-project}
## Organising your projects {#organising-your-projects}
## Creating an R Script {#creating-an-r-script}
## Using R Markdown {#r-markdown-and-r-notebooks}

<!--chapter:end:06_starting_r_projects.Rmd-->


# Data Wrangling {#data-wrangling}

Placeholder


## Import your data
### Import data from the Files pane
### Importing data from the Environment pane {#importing-data-from-the-environment-pane}
### Importing data using functions directly {#importing-data-using-functions}
## Inspecting your data {#inspecting-raw-data}
## Cleaning your column names: Call the `janitor` {#colnames-cleaning}
## Data types: What are they and how can you change them {#change-data-types}
## Handling factors {#handling-factors}
### Recoding factors {#recoding-factors}
### Reordering factor levels {#reordering-factor-levels}
## Dealing with missing data {#dealing-with-missing-data}
### Mapping missing data {#mapping-missing-data}
### Identifying patterns of missing data {#patterns-of-missing-data}
#### Missing completely at random (MCAR) {#missing-completetly-at-random-mcar}
#### Missing at random (MAR) {#missing-at-random-mar}
#### Missing not at random (MNAR) {#missing-not-at-random-mnar}
### Replacing or removing missing data {#replacing-removing-missing-data}
### Main takeaways regarding dealing with missing data
## Latent constructs and their reliability {#latent-constructs}
## Once you finished with data wrangling {#conclusion-data-wrangling}

<!--chapter:end:07_data_wrangling.Rmd-->


# Descriptive Statistics {#descriptive-statistics}

Placeholder


## Plotting in R with `ggplot2` {#plotting-in-r-with-ggplot2}
## Central tendency measures: Mean, Median, Mode {#central-tendency}
### Mean
### Median
### Mode {#mode}
## Indicators and visualisations to examine the spread of data {#spread-of-data}
### Boxplot: So much information in just one box
### Histogram: Do not mistake it as a bar plot
### Density plots: Your smooth histograms
### Violin plot: Your smooth boxplot
### QQ plot: A 'cute' plot to check for normality in your data {#qq-plot}
### Standard deviation: Your average deviation from the mean {#standard-deviation}

<!--chapter:end:08_descriptive_statistics.Rmd-->


# Sources of bias: Outliers, normality and other 'conundrums' {#sources-of-bias}

Placeholder


## Linearity and additivity {#additivity-and-linearity}
## Independence
## Normality {#normality}
## Homogeneity of variance (homoscedasticity) {#homogeneity-of-variance}
## Outliers and how to deal with them {#dealing-with-outliers}
### Detecting outliers using the standard deviation {#ouliers-standard_deviation}
### Detecting outliers using the interquartile range {#outliers-iqr}
### Removing or replacing outliers {#removing-or-replacing-outliers}

<!--chapter:end:09_sources_of_bias.Rmd-->


# Correlations {#correlations}

Placeholder


## Parametric or non-parametric: That is the question {#parametric-or-non-parametric}
## Plotting correlations {#plotting-correlations}
## Significance: A way to help you judge your findings {#significance}
## Limitations of correlations {#limitations-of-correlations}
### Correlations are not causal relationships {#correlations-are-not-causal-relationships}
### Correlations can be spurious {#correlations-can-be-spurious}
### Simpson's Paradox: When correlations betray you {#simpsons-paradox}

<!--chapter:end:10_correlations.Rmd-->

# Comparing groups

```{r echo=FALSE}
library(tidyverse)
library(r4np)
library(broom)
library(effectsize)

wvs_nona <- read_csv("wvs_nona.csv") %>% 
  mutate_if(is.character, as_factor)
```

Social Sciences is about the study of human beings and their interactions. As such, we frequently want to compare two or more groups of human beings, organisations, teams, countries, etc., with each other to see whether they are similar or different from each other. Sometimes we also want to track individuals over time and see how they may have changed in some way or other. In short, comparing groups is an essential technique to make inferences and helps us better understand the diversity that surrounds us.

If we want to perform a group comparison we have to consider which technique is most appropriate for the data we have. Some of it might be related to the type of data we have collected, other aspects might be linked to the distribution of the data. More specifically, before we apply any statistical technique we have to consider at least the following:

-   missing data (see Chapter \@ref(dealing-with-missing-data)),

-   outliers (see Chapter \@ref(dealing-with-outliers), and

-   the assumptions made by analytical techniques about our data.

While we covered missing data and outliers in previous chapters, we have yet to discuss assumptions. For group comparisons there are three main questions we need to answer:

-   Are the groups big enough to be compared, i.e. are they comparable?

-   Is my data parametric or non-parametric? (see Chapter \@ref(parametric-or-non-parametric))

-   How many groups do I wish to compare?

-   Are these groups paired or unpaired?

In the following we will look at group comparisons for parametric and non-parametric data in each category and use the `wvs_nona` dataset, i.e. the `wvs` data frame after we performed imputation (see also Chapter \@ref(replacing-removing-missing-data)). Since we already covered how to test whether data is parametric or non-parametric we will forgo this step out of pure convenience and to remain succinct. We also ignore any potential outliers or missing data. The case studies at the end of the book provide realistic examples of how to perform groups comparisons with a new set of data from start to finish (see Chapter \@ref()). Thus, parametric and non-parametric tests will be demonstrated with the same dataset and the same variables.

## Comparability: Apples vs Oranges {#comparability-apples-vs-oranges}

Before we can jump into group comparisons we need to make ourselves aware of whether our groups can be compared in the first place. 'Comparability' should not be confused with 'are the groups equal'. In many cases, we don't want groups to be equal in terms of participants, e.g. between-subject studies. On the other hand, we might want groups to be perfectly equal when we perform within-subject studies. Thus, asking whether groups are comparable is unrelated to whether the subjects in our study are the same. Instead, we are looking at characteristics of our groups. Some commonly considered characteristics include:

-   *size*: Are the groups about equally large?

-   *time*: Was the data collected around the same time?

-   *exogenous variables*: Is the distribution of characteristics we are not interested in, approximately the same across groups?

When we compare groups we want to minimise the systematic differences that are not the primary focus of our study. Using the right sampling technique can help with this matter. For example, using a random sample and performing a random allocation to groups can help with achieving comparable groups and remove systematic differences in a way no other sampling strategy can. However, there is still no guarantuee that they will be comparable (see also @altman1985comparability and @berger2006review). Besides, we also face the challenge that in Social Sciences we do not have the option of random sampling. For example, International Business studies heavily rely on lists provided by others, e.g. the European Union, Fortune 500, etc., personal judgement and convenience sampling and only a small proportion actually perform probability sampling [@yang2006-IBmethods]. In short, there is no reason to worry if your sampling technique is not random to begin with. However, it emphasises the need to understand your sample and your groups thoroughly.

In order to inspect characteristics of groups we wish to compare, we can use descriptive statistics as we covered them in Chapter \@ref(descriptive-statistics). The only aspect that is different is that we apply these techniques to subsets of our data and not the entire dataset.

For example, we might wish to compare female and male Egyptians (see Chapter \@ref(two-unpaired-groups)). If we wanted to make sure these two groups can be compared we might have to check (among other characteristics) whether their age is distributed similarly. We can use the functions we already know to create a plot to investigate this matter. We could either use a boxplot, or, a bit more accurate, a density plot using the `ggridges` package.

```{r Comparability of Egyptians, echo=TRUE, message=FALSE}
# Only select participants from 'Egypt'
comp <- wvs_nona %>%
  filter(country == "Egypt")

comp %>%
  ggplot(aes(x = age,
             y = gender,
             fill = gender)) +
  ggridges::geom_density_ridges(bandwidth = 4)
```

As we can see, the distribution of `age` across both `gender` groups is fairly similar and likely not different between groups. Of course, we could also statistically explore this using a suitable test before performing the main group comparison. However, we first have to understand how we can perform them.

In the following chapters we will largely rely on built-in functions to perform our group comparisons. However, there are packages available, such as `statsExpressions`, which offer a more standardised way of performing them. Still, these are usually 'wrappers' around the basic functions, i.e. at their core they rely on the same basic functions.

## Comparing two groups {#comparing-two-groups}

The simplest of comparisons is the one where you only have two groups. These groups could either consist of different people (unpaired) or represent two measurements of the same individuals (paired).

### Two Unpaired groups {#two-unpaired-groups}

An unpaired group test assumes that the observations in each group are not related to each other, for example that the participants in each group are different individuals.

Our first comparison will be participants from `Egypt` and we want to understand whether male and female citizens in this country perceive that they have `freedom_of_choice`.

We first can compare these two groups using our trusty `geom_boxplot` (or any variation of it).

```{r Two unpaired groups visualisation, echo=TRUE}
# Compute the mean for and size of each group 
group_means <- comp %>% 
  group_by(gender) %>% 
  summarise(g_mean = mean(freedom_of_choice),
            n = n())

group_means

# Create our data visualisation
comp %>% 
  ggplot(aes(x = gender, y = freedom_of_choice, fill = gender)) +
  geom_boxplot() +
  
  # Add the mean for each group
  geom_point(data = group_means,
             aes(x = gender, y = g_mean),
             shape = 3,
             size = 2
             )
```

While the distribution looks similar, we can notice that the median and the mean (marked by the cross inside the boxplot) are slighter higher for `male` participants. Thus, we can suspect slight differences between these two groups, but we do not know whether these differences are significant or not. To consider the significance (remember Chapter \@ref(significance)) and the effect size (see Table \@ref(tab:effect-size-cohen)) we have to perform statistical tests.

Table \@ref(tab:comparing-two-groups-unpaired) summarises the different tests and functions to perform the group comparison computationally. It is important to note that the parametric test compares the means of two groups, while the non-parametric test compares medians. All of these tests turn significant if the differences between groups is large enough. Thus, significant results can be read as 'these groups are significantly different from each other'. Of course, if the difference is not significant, the groups are considered to be not different from each other. For parametric tests, i.e. `t.test(),` it is also important to indicate whether the variances between these two groups are equal or not. Remember this was one of the assumptions for parametric tests. The Welch t-test can be used if the variances are not equal, but all other criteria for normality are met. By setting `var.equal = TRUE`, a regular T-Test would be performed. By defaulty, `t.test` assumes that variances are not equal. Make sure you test for homogeneity of variance before making your decision (see Chapter \@ref(homogeneity-of-variance).

+----------------+----------------+-------------------------------+-----------------+-------------------+
| Assumption     | Test           | Function                      | Effect size     | Function          |
+================+================+===============================+=================+===================+
| Parametric     | T-Test         | `t.test(var.equal = TRUE)`    | Cohen's d       | `cohens_d()`      |
|                |                |                               |                 |                   |
|                | Welch T-Test   | `t.test(var.equal = FALSE)`   |                 |                   |
+----------------+----------------+-------------------------------+-----------------+-------------------+
| Non-parametric | Mann-Whitney U | `wilcox.test(paired = FALSE)` | Rank-biserial r | `rank_biserial()` |
|                |                |                               |                 |                   |
|                |                |                               | or              | or                |
|                |                |                               |                 |                   |
|                |                |                               | Wilcoxon R      | `wilcoxonR()`     |
+----------------+----------------+-------------------------------+-----------------+-------------------+

: (\#tab:comparing-two-groups-unpaired)Comparing two unpaired groups (effect size functions from package `effectsize`, except for `wilcoxonR()` from `rcompanion`

With this information in hand, we can start comparing the female Egyptians with the male Egyptians using the parametric and the non-parametric test for illustration purposes only.

```{r Computation two unpaired groups, echo=TRUE}
# T-Test
t.test(freedom_of_choice ~ gender,
       data = comp,
       var.equal = TRUE
       )

# Welch t-test
t.test(freedom_of_choice ~ gender,
       data = comp,
       var.equal = FALSE
       )

# Mann-Withney U test
wilcox.test(freedom_of_choice ~ gender, data = comp)
```

You might notice that the notation within the functions for group tests looks somewhat different to what we are used to, i.e. we use the `~` ('tilde') symbol. Some functions take a formula as their attribute and to distinguish the dependent and independent variable from each other we use `~`. A more generic notation of how formulas in functions work is shown below, where `DV` stands for dependent variable and `IV` stands for independent variable:

::: {#formulas-in-functions align="center"}
function(formula = DV \~ IV_01 + IV_02, data = your_data)
:::

Group comparisons, even for multiple groups, we usually only have one independent variable, i.e. the grouping variable. Grouping variables are usually of the type `factor`. In case of two groups, we have two levels present in this factor, e.g. `gender`. If there are multiple groups, the factor contains multiple levels, e.g. `country`.

No matter which test we run, it appears as if the difference is significant. However, how big is the difference? The answer to this is provided by the effect size. The interpretation of what the effect size is, follows the explanations in Chapter \@ref(correlations), where we looked at the strength of the correlation of two variables. However, different effect size measures imply that we have to use different benchmarks. To help us a bit with the interpretation we can use the `correlation` package and their set of `interpret_...()` functions (see also [Indices of Effect Size](https://easystats.github.io/effectsize/articles/interpret.html "Indices of Effect Size"){target="blank"}). Sometimes, there are even more than one way of computing the effect size. For example for the Mann-Whitney test we can choose between the classic Wilcoxon R, computed as $\frac{Z}{\sqrt{n}}$ or the rank-biserial correlation coefficient. In practice, you have to be explicit about how you computed the effect size. The differences between the two measures are often marginal and a matter of taste (or should I say: Your reviewers' taste). Throughout this chapter I will rely on the effect sizes most commonly found in Social Sciences publications. However, feel free to explore other indices as well.

```{r Computation of effect size of two unpaired groups, echo=TRUE}

## After T-Test or Welch T-Test
d <- cohens_d(freedom_of_choice ~ gender,
              data = comp,
              paired = FALSE,
              var.equal = TRUE)

interpret_d(d$Cohens_d)

## After Mann-Whitney U test
(rb <- rank_biserial(freedom_of_choice ~ gender, data = comp))

interpret_rank_biserial(rb$r_rank_biserial, rules = "cohen1988")
# or
(wr <- rcompanion::wilcoxonR(comp$freedom_of_choice, comp$gender))

interpret_r(wr)

```

Looking at our test results, both approaches produce significant results, i.e. the female Egyptians perceive `freedom_of_choice` differently from their male counterparts. This is in line with our boxplots. However, the effect sizes tend to be small, which means the differences between the two groups is marginal. Similar to correlations, group comparisons need to be analysed in two stages answering two questions:

1.  Is the difference between groups significant?

2.  Is the difference small, medium or large?

The combination of both analytical steps gives us a comprehensive answer to our research question and enables us to derive with meaningful conclusions.

### Two Paired groups {#two-paired-groups}

Sometimes, we are not interested in the difference between subjects, but within them, i.e. we want to know whether the same person provides similar or different responses at two different times. Thus, it becomes evident that observations need to be somehow linked to each other. Paired groups are often found and used in longitudinal studies and in experimental studies (e.g. pre-test vs post-test). For example, in the field of Intercultural Communication, one might be interested to understand whether participants who took part in training to improve their intercultural communication skills have improved or not. This could be indicative of the effectiveness of the training or the ability of participants to retain and apply information to their workplace settings.

If we look at our `imdb_top_250` dataset we can see that some directors have more than one movie in the top 250. Therefore, we could be curious to know whether the earlier movies of directors has been significantly more successful than their later movies.

```{r Directors and their movies, echo=TRUE}
imdb_top_250 %>%
  group_by(director) %>%
  summarise(n = n()) %>%
  arrange(desc(n))
```

For this investigation we use the modified dataset `dir_mov` which only contains movies of directors who have two or more movies listen in the IMDb Top 250s. Where directors had more than two movies, I randomly sampled two movies. Thus, there is a certain limitation to our dataset.

We can use boxplots to compare earlier movies (i.e. `1`) with later movies (i.e. `2`) across all directors. Thus, each director is reflected in both groups with one of their movies and therefore the same directors can be found in each group. As a measure of success we use the `imdb_rating`.

```{r Comparing two paired groups data visualisation boxplot, echo=TRUE}
dir_mov %>% 
  ggplot(aes(x = movie, y = imdb_rating, fill = movie)) +
  geom_boxplot()
```

The boxplots look almost identical which suggests that the rating of movies in both groups has not changed significantly. However, the boxplot can only show a summary statistics for each group. Thus, it only implies that the movies in group `1` have about the same ratings as the movies in `2`. If we want to visualise how the ratings have changed for each director from the first to the second movie, we can create a point plot and draw lines with `geom_line()` to connect the movies in each group. A line that movies up indicates that the second movie was rated higher than the first one and vice versa.

```{r Comparing two paired groups data visualisation line plot, echo=TRUE}
dir_mov %>%
  ggplot(aes(x = movie, y = imdb_rating, colour = director)) +
  geom_point() +
  geom_line(aes(group = director)) +
  # Remove the legend
  theme(legend.position = "none")
```

Based on this plot we have to revise our interpretation slightly. Directors who received particularly high ratings on their first movie (i.e. the top 3) scored much lower on the second movie. For once, we noticed from our boxplots that these movies count as outliers, and second, obtaining such high scores on a movie is tough to replicate. Needless to say, all these movies are rated as very good, otherwise they would not be in this list. It is worth noting that the way the y axis is scaled emphasises differences. Thus, a difference between a rating of 9 and 8.5 appears large. If we change the range of the y axis to '0-10', the differences appear marginal, but it reflects (1) the possible length of the scale (IMDb ratings range from 0-10) and (2) the magnitude in change relative to the entire scale.

```{r Comparing two paired groups data visualisation line plot and full y scale, echo=TRUE}
dir_mov %>%
  ggplot(aes(x = movie, y = imdb_rating, colour = director)) +
  geom_point() +
  geom_line(aes(group = director)) +
  # Remove the legend
  theme(legend.position = "none")+
  # Manuall define the y axis range
  ylim(0,10)
```

Considering this plot, we likely can predict what the statistical test will show. Table \@ref(tab:comparing-two-groups-paired) summarises which tests and functions need to be performed if our data is parametric or non-parametric. In both cases, the functions are the same, but we need to add the attribute `paired = TRUE`. The interpretations between the unpaired and paired tests remain the same.

+----------------+---------------------------+-------------------------------------------------+-----------------+--------------------------+
| Assumption     | Test                      | Function for test                               | Effect size     | Function for effect size |
+================+===========================+=================================================+=================+==========================+
| Parametric     | T-Test                    | `t.test(var.equal = TRUE/FALSE, paired = TRUE)` | Cohen's d       | `cohens_d()`             |
+----------------+---------------------------+-------------------------------------------------+-----------------+--------------------------+
| Non-parametric | Wilcoxon Signed Rank Test | `wilcox.test(paired = TRUE)`                    | Rank biserial r | `rank_biserial()`        |
|                |                           |                                                 |                 |                          |
|                |                           |                                                 | or              | or                       |
|                |                           |                                                 |                 |                          |
|                |                           |                                                 | Wilcoxon r      | `wilcoxonPairedR()`      |
+----------------+---------------------------+-------------------------------------------------+-----------------+--------------------------+

: (\#tab:comparing-two-groups-paired)Comparing two unpaired groups (effect size functions from package `effectsize`, except for `wilcoxonPairedR()` from `rcompanion`)

Let's apply the functions to find out whether the differences we can see in our plots matter.

```{r Comparing two paired groups data computation, echo=TRUE, warning=FALSE}
# PARAMETRIC COMPARISON

## Perform the comparison
t.test(imdb_rating ~ movie,
                 data = dir_mov,
                 paired = TRUE,
                 var.equal = TRUE
       )

## Determine the effect size
(d <- cohens_d(imdb_rating ~ movie,
               data = dir_mov,
               paired = TRUE,
               var.equal = TRUE))

## Interpret the effect size
interpret_d(d)

# NON-PARAMETRIC COMPARISON

## Perform the comparison
wilcox.test(imdb_rating ~ movie,
            data = dir_mov,
            paired = TRUE)

## Determine the effect size via rank biserial correlation
(d <- rank_biserial(imdb_rating ~ movie, data = dir_mov))

## Interpret the effect size
interpret_rank_biserial(d$r_rank_biserial, rules = "cohen1988")
```

As expected, the paired tests reveal that the differences in rating between the first movie and the second movie are not significant and the effect sizes are very small, irrespective of whether we treat our data as parametric or non-parametric. Remember, if group comparisons are not significant, there is no need to compute effect sizes. However, for demonstration purposes I included it in this example.

## Comparing more than two groups {#comparing-more-than-two-groups}

Often we find ourselves in situations were comparing two groups is not enough. Instead, we might be faced with three or more groups fairly quickly. For example, the `wvs` dataset let's us look at 48 different countries, all of which we could compare very quickly with just a few lines of code. In the following chapters we look at how we can perform the same type of analysis for multiple unpaired and paired groups using R. Similarly to the two-samples group comparison, we cover the parametric and non-parametric approaches.

### Multiple unpaired groups {#multiple-unpaired-groups}

Have you been wondering whether people in different countries are equally satisfied with their lives? You might have a rough guess that it is not the case, because the social, economic and political environment might place an import role. If you live in a country that is affected by social conflicts, one's life satisfaction might be drastically lower. In the following we take a look at three countries `Iraq`, `Japan` and `Korea`. I did not chose these countries out of personal interest, but because they nicely demonstrate the purpose of the chapter, i.e. finding out whether there are differences in the perception of `satisfaction` across three countries. At any time, feel free to remove the `filter()` function to gain the results of all countries in the dataset, but prepare for slightly longer computations.

Similar to before, we can use the `ggridges` package to draw density plots for each group. This has the added benefit that we can compare the distribution of data for each group and see whether the assumption of normality is likely met or not. On the other hand, we lose the option to identify any outliers. You win some and you lose some.

```{r Multiple unpaired groups data visualisation, echo=TRUE}
mcomp <- wvs_nona %>%
  filter(country == "Iraq" |
           country == "Japan" |
           country == "Korea")

mcomp %>%
  group_by(country) %>%
  ggplot(aes(x = satisfaction,
             y = reorder(country, satisfaction),
             fill = country)) +
  ggridges::stat_density_ridges(bandwidth = 0.6,
                                quantile_lines = TRUE,
                                quantiles = (0.5)) +      # adds the median indicator
  # Remove legend
  theme(legend.position = "none")
```

The plot shows us that `Japan` and `Korea` appear to be very similar if not identical (based on the median), but `Iraq` appears to be different from the other two groups. When performing a multiple group comparison we can follow similar steps as before for comparing two groups, i.e.

-   perform the comparison,

-   determine the effect size, and

-   interpret the effect size.

Table \@ref(tab:comparing-multiple-groups-unpaired) summarises which test needs to be chosen to compare multiple unpaired groups and their corresponding effect size measures.

+----------------+----------------------+-------------------------------------------+------------------------+--------------------------+
| Assumption     | Test                 | Function for test                         | Effect size            | Function for effect size |
+================+======================+===========================================+========================+==========================+
| Parametric     | ANOVA                | -   `aov()` (assumes equal variances)     | Cohen's d              | `eta_squared()`          |
|                |                      | -   `oneway.test(var.equal = TRUE/FALSE)` |                        |                          |
+----------------+----------------------+-------------------------------------------+------------------------+--------------------------+
| Non-parametric | Kruskall-Wallis test | `kruskal.test()`                          | Epsilon squared (rank) | `rank_epsilon_squared()` |
+----------------+----------------------+-------------------------------------------+------------------------+--------------------------+

: (\#tab:comparing-multiple-groups-unpaired)Comparing multiple unpaired groups (effect size functions from package `effectsize`)

```{r Multiple unpaired groups computation, echo=TRUE, message=FALSE}
# PARAMETRIC COMPARISON

## Perform comparison
### Equal variances assumed
results_aov <- aov(satisfaction ~ country, data = mcomp) %>%
  broom::tidy()

### Equal variances not assumed
oneway.test(satisfaction ~ country,
            data = mcomp,
            var.equal = FALSE)


## Determine the effect size
(eta <- eta_squared(results_aov))

eta_squared(aov(satisfaction ~ country, data = mcomp))

## Interpret the effect size
interpret_eta_squared(eta$Eta2)

## NON-PARAMETRIC COMPARISON

## Perform comparison
(kk <- kruskal.test(mcomp$satisfaction, mcomp$country))

## Determine the effect size
(es <- rank_epsilon_squared(kk))

## Interpret effect size
interpret_epsilon_squared(es$rank_epsilon_squared)
```

The results show that there is a significant and large difference between these groups. You might argue that this is actually not quite true. Considering our plot, we know that Japan and Korea do not look like as if they are significantly different. Multiple group comparisons only consider differences across all three groups. Therefore, if one group lies far away from the other groups, the test will turn significant and even provide a large enough effect size to consider it important. However, these tests do not provide information which differences between groups are significant. To gain more clarification about this, we need to incorporate another step, so called 'post-hoc tests'. These tests compare two groups at a time, which is why they are also known as 'pairwise comparisons'. Compared to regular two-sample tests, these perform corrections of the `p`values for mulitple testing, which is necessary. However, there are many different 'post-hoc' tests one can choose from. @field2013discovering (p.459) nicely outlines the different scenarios and provides recommends to navigate this slightly complex field of post-hoc tests to follow-up a one-way ANOVA. Table \@ref(tab:post-hoc-tests) provides an overview of his suggestions.

+----------------------------------+-----------------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Equal sample size                | Equal variances | Post-hot tests     | Functions in R                                                                                                                                                                                   |
+==================================+=================+====================+==================================================================================================================================================================================================+
| YES                              | YES             | -   REGWQ,         | -   `mutoss::regwq()`[^group_comparison-1]                                                                                                                                                       |
|                                  |                 |                    |                                                                                                                                                                                                  |
|                                  |                 | -   Tukey,         | -   `TukeyHSD()`                                                                                                                                                                                 |
|                                  |                 |                    |                                                                                                                                                                                                  |
|                                  |                 | -   Bonferroni     | -   `pairwise.t.test(p.adjust.method = "bonferroni")`                                                                                                                                            |
+----------------------------------+-----------------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| NO (slightly different)          | YES             | -   Gabriel        |                                                                                                                                                                                                  |
+----------------------------------+-----------------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| YES                              | YES             | -   Hochberg's GT2 | -   Not available in R and should not be confused with `pairwise.t.test(p.adjust.method = "hochberg")`, which is based on @hochberg1988sharper. The GT2, however, is based on @hochberg1974some. |
+----------------------------------+-----------------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| NO (not ideal for small samples) | NO              | -   Games-Howell   | -   `rstatix::games_howell_test()`                                                                                                                                                               |
+----------------------------------+-----------------+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

: (\#tab:post-hoc-tests) Different post-hoc tests for different scenarios

[^group_comparison-1]: In order to use this package, it is necessary to install a series of other packages found on [bioconductor.org](https://www.bioconductor.org "bioconductor.org"){target="blank"}

You might be surprised to see that there are also post-hoc tests for parametric group comparisons when the assumption of equal variances is not assumed. Would we not have to use a non-parametric test for our group comparison instead? Well, empirical studies have demonstrated that ANOVAs tend to produce robust results, even if the assumption of normality (e.g. @blanca2017non) is not given, or there are some degree of heterogeneity of variance between groups [@tomarken1986comparison]. In other words, there can be some leniancy (or flexibility?) when it comes to the violation of parametric assumptions. If you want to reside on the save side, you should ensure you know your data and its properties. If in doubt, non-parametric tests are also available.

If we want to follow up the Kruskall-Wallis test, we can make use of two post-hoc tests:

-   Dunn Test: `dunn.test::dunn.test()` [@dinno2015nonparametric]
-   Pairwise comparison with Bonferroni (and other) correction: `pairwise.wilcox.test()`.

Below are some examples of how you would use these functions in your project. However, be aware that some of the post-hoc tests are not or not well implemented yet in R. Here I show the most important ones which likely serve you in 90% of the cases.

```{r Multiple group comparison post-hoc tests, echo=TRUE}
# POST_HOC TEST FOR PARAMETRIC DATA
# Bonferroni
pairwise.t.test(mcomp$satisfaction, mcomp$country, p.adjust.method = "bonferroni")

# Tukey
TukeyHSD(results_aov)

# Games-Howell
rstatix::games_howell_test(satisfaction ~ country,
                           data = mcomp)

# POST-HOC TEST FOR NON-PARAMETRIC DATA
pairwise.wilcox.test(mcomp$satisfaction, mcomp$country, p.adjust.method = "holm")
# or
dunn.test::dunn.test(mcomp$satisfaction, mcomp$country)
```

As we can see, no matter which function we use, the interpretation of the results remain the same on this occasion.

### Multiple paired groups {#multiple-paired-groups}

Additional condition if you compare three or more groups with each other. Might not be good to call them groups actually, because it refers to different measures by the same person usually over an extended period of time.

Is an extension of the linear model - so why not simply use a regression instead. Is it because regression primarily use quantitative data and not categorical type data?

repeated measures ANOVA (find dataset)

```{r Repeated measures ANOVA, echo=TRUE}
rstatix::anova_test()

eta_squared()
omega_squared()
```

Friedman Test (find dataset)

```{r Friedman test, echo=TRUE}
# NON=PARAMETRIC COMPARISON
friedman.test()

# Effect size
kendalls_w()
```

A useful overview of all the possible options of comparing groups and how to obtain their effect sizes can also be found here

<https://indrajeetpatil.github.io/statsExpressions/articles/stats_details.html>

## Comparing groups based on factors: Contingency tables {#chi-squared-test}

Unpaired

```{r Contigency tables unpaired computation, echo=TRUE}
chisq.test()
cramers_v()
```

Paired

```{r Contigency tables paired computation, echo=TRUE}
mcnemar.test()

# Effect size
cohens_g()
```

## A cheatsheet to guide your own group comparisons {#cheatsheet-group-comparisons}

To summarise what we have covered in this section, we can consider

```{r How to decide on the right group comparison, echo=FALSE}
DiagrammeR::mermaid("
        graph TB

        data(my data)
        datatype{type of data}
        quan[quantitative]
        qual[qualitative]
        paracheck{<center>check for <br> assumptions</center>}
        addlin[additivity and linerarity]
        normal[normality]
        homvar[homogeneity of variance]
        indep[independence]
        para[parametric]
        npara[non-parametric]
        
        data --> datatype
        
        subgraph 
        datatype --> quan
        datatype --> qual
        end
        
        
        quan --> paracheck
        qual --> npara
        
        paracheck --> addlin
        
        subgraph 
        addlin -- yes --> indep
        indep -- yes --> normal
        normal -- yes --> homvar
        end

        addlin -- no --> npara
        indep -- no --> npara
        normal -- no --> npara
        homvar -- no --> npara

        homvar -- yes --> para
        
        # hwg[How many groups?]
        ")


```

<!--chapter:end:11_group_comparison.Rmd-->

# Regression: Creating models to predict future observations {#regression}

<!--chapter:end:11_regressions.Rmd-->

# Mixed-methods research: Analysing qualitative in R

<!--chapter:end:12_mixed_methods.Rmd-->

# Where to go from here: The next steps in your R journey {#next-steps}

## GitHub: A Gateway to even more ingenious R packages {#next-steps-github}

## Books to read and expand your knowledge {#next-steps-books}

## Engage in regular online readings about R {#next-steps-online-readings}

-   Tidyverse Blog
-   R-blogger

## Join the Twitter community and hone your skills {#next-steps-twitter}

-   \#RStats
-   TidyTuesday

<!--chapter:end:13_next_steps.Rmd-->

# Appendix {-}

## Comparing two unpaired groups


<!--chapter:end:99_appendix.Rmd-->


# Exercises: Solutions {#exercises-solutions}

Placeholder


## Solutions for 5.6 {#exercises-solutions-5}

<!--chapter:end:99_exercise_solutions.Rmd-->

