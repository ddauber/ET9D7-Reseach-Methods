[["descriptive-statistics.html", "8 Descriptive Statistics 8.1 Plotting in R with ggplot2 8.2 Central tendency measures: Mean, Median, Mode 8.3 Indicators and visualisations to examine the spread of data", " 8 Descriptive Statistics The best way to understand how participants in your study have responded to various questions or an experimental treatment is to use descriptive statistics. As the name indicates, their main purpose is to ‘describe.’ Most of the time we want to describe the composition of our sample and likely how the majority (or minority) of participants performed. In contrast, we use ‘inferential’ statistics to make predictions about the future. In Social Sciences, we are often interested in predicting how people will behave in certain situations and scenarios. We aim to develop models that help us navigate the complexity of social interactions that we all engage in, but might not fully understand. We cover ‘inferential statistics’ in later chapters of this book. In short, descriptive statistics are an essential component to understand your data. To some extend, one could argue that we were already describing our data when we performed various data wrangling tasks (see Chapter 7. The following chapters focus on the most essential descriptive statistics, i.e. the ones you likely want to investigate in 99 out of 100 research projects. This book takes a ‘visualise first’ approach to data analysis. Therefore, each section will start with data visualisations, followed by computing statistical output, and end with how we can report our results in publications of all kind. A key learning outcome of this chapter is to plot your data using the package ggplot2 and to present characteristics of your data in different ways. Each chapter will ask questions about our dataset that we aim to answer. However, first we need to understand how to create plots in R. 8.1 Plotting in R with ggplot2 Plotting can appear intimidating at first, but is very easy and quick, once you understand the basics. The ggplot2 package is a very popular package to generate plots in R and many other packages are built upon it. This makes it a very flexible tool to create almost any data visualisation you could think of. If you want to see what is possible with ggplot2 you might want to consider looking at #tidytuesday on Twitter where novices and veterans share their data visualisations on a weekly basis. To generate any plot we need to at least define three components: a dataset, variables we want to plot, and how we want to plot them, e.g. as lines, bars, points, etc. Admittedly, this is a harsh oversimplification, but it will serve as a useful guide to get us started. The function ggplot() is the one responsible to create any type of data visualisation. The generic structure of a ggplot() looks like this: ggplot(data, aes(x = variable_01, y = variable_02)) In other words, we first need to provide the dataset data, and then the aesthetics (aes()). Think of aes() as the place where we define our variables (i.e. x and y). For example, we might be interested to know which movie genre is the most popular among the top 250 IMDb movies. The dataset imdb_top_250 from the r4np package allows us to find an answer to this question. Therefore we define the components of the plot as follows: our data is imdb_top_250, and our variable of interest is genre_01 ggplot(imdb_top_250, aes(x = genre_01)) Running this line of code will produce an empty plot. We only get labels for our x-axis, since we defined it already. However, we have yet to tell ggplot() how we want to represent the data on this canvas. Your choice for how you want to plot your data is usually informed by the type of data you want to plot and the statistics you want to represent. For example trying to plot the mean of a factor is not useful, e.g. computing the mean of movie genres. On the other hand, we can count how often certain genres appear in our dataset. One way of representing the count (or frequency) of a factor is to use a bar plot. In order to add an element to ggplot(), i.e. bars, we use + and append the function geom_bar() which draws bars. The + operator works similar to %&gt;% and allows to chain multiple functions one after the other. ggplot(imdb_top_250, aes(x = genre_01)) + geom_bar() This already looks great and we can see that Drama is by far the most popular genre, followed by Action and Crime. Thus, we successfully found an answer to our question. Still, there are more improvements necessary to use it in a publication. We can use + to add other elements to our plot, such as a title and proper axes labels. Here are some common functions to further customise our plot: ggplot(imdb_top_250, aes(x = genre_01)) + geom_bar() + ggtitle(&quot;Most popular movie genres&quot;) + # Add a title xlab(&quot;movie genre&quot;) + # Rename x-axis ylab(&quot;frequency&quot;) # Rename y-axis When working with factors, the category names can be rather long. In this plot, we also have lots of categories and the labels Adventure, Animation and Biography are a bit too close to each other for my taste. This might be a good opportunity to use coord_flip(), which rotates the entire plot by 90 degrees, i.e. turning the x-axis into the y-axis and vice versa. This makes the label much easier to read. ggplot(imdb_top_250, aes(x = genre_01)) + geom_bar() + ggtitle(&quot;Most popular movie genres&quot;) + xlab(&quot;movie genre&quot;) + ylab(&quot;frequency&quot;) + coord_flip() Our plot is almost perfect, but there is one more step we should take to make reading and understanding this plot even easier. At the moment, the bars are ordered alphabetically by movie genre. This is hardly ever a useful way to order your data. Instead, we might want to sort the data by the frequency, showing the most popular genre at the top. We could either sort the movies by hand or slightly amend what we have coded so far. The problem you encounter when rearranging a geom_bar() with only one variable is that we do not have an explicit value we can use to indicate how we want to sort the bars. Our current code is based on the fact that ggplot does the counting for us. So, instead we need to do two things: create a table with all genres and their frequency, and use this table to plot the genres by the frequency we computed # Step 1: The frequency table only imdb_top_250 %&gt;% count(genre_01) ## # A tibble: 11 × 2 ## genre_01 n ## &lt;fct&gt; &lt;int&gt; ## 1 Action 40 ## 2 Adventure 20 ## 3 Animation 24 ## 4 Biography 22 ## 5 Comedy 23 ## 6 Crime 38 ## 7 Drama 72 ## 8 Film-Noir 1 ## 9 Horror 3 ## 10 Mystery 4 ## 11 Western 3 # Step 2: Plotting a barplot based on the frequency table imdb_top_250 %&gt;% count(genre_01) %&gt;% ggplot(aes(x = genre_01, y = n)) + geom_col() + # Use geom_col() instead of geom_bar() ggtitle(&quot;Most popular movie genres&quot;) + xlab(&quot;movie genre&quot;) + ylab(&quot;frequency&quot;) + coord_flip() #Step 3: Sort the plot by frequency, i.e. by &#39;n&#39; imdb_top_250 %&gt;% count(genre_01) %&gt;% ggplot(aes(x = reorder(genre_01, n), y = n)) + # Use &#39;reorder()&#39; geom_col() + ggtitle(&quot;Most popular movie genres&quot;) + xlab(&quot;movie genre&quot;) + ylab(&quot;frequency&quot;) + coord_flip() Step 3 is the only code you need to create the desired plot. The two other steps are a mean to demonstrate how one can slowly built up this plot, step-by-step. You might have noticed that I used dplyr to chain all these functions together and therefore it was not necessary to specify the dataset in ggplot(). There are also two new functions we had to use: geom_col() and reorder(). The functions geom_col() and geom_bar() can be confusing. The easiest way to remember how to use them is: If you use a frequency table to create your barplot, use geom_col, if not, use geom_bar(). The function geom_col() requires that we specify a y-axis (our frequency scores), while geom_bar() does not. In many cases, when creating plots you have to perform two steps: generate the statistics you want to plot, e.g. a frequency table, and plot the data via ggplot() Now you have learned the fundamentals of plotting in R. Throughout the next chapters we will create a lot more plots. They all share the same basic structure, but we will use different ‘geoms’ to describe our data. By the end of this book, you will have accrued enough experience in plotting in R that it will feel like second nature. If you want to deepen your knowledge of ggplot, you should take a look at the book ‘ggplot: Elegant Graphics for Data Analysis’ or ‘R Graphics Cookbook’ which moves beyond ggplots. 8.2 Central tendency measures: Mean, Median, Mode The mean, median and mode (the 3 Ms), are all measures of central tendency, i.e. they provide insights into how our data is distributed. All three of these measures summarise our data/variable by a single score which can be helpful, but sometimes also terribly misleading. 8.2.1 Mean The mean is likely the most known descriptive statistics and, at the same time, a very powerful and influential one. For example, the average ratings of restaurants on Google might influence our decision on where to eat out. Similarly, we might consider the average rating of movies to decide which one to watch in cinema with friends. What we casually refer to as the ‘average’ is equivalent to the ‘mean.’ In R it is simple to compute the mean using the function mean(). We used this function in Chapter 5.3 and Chapter 7.7 already. However, we have not looked at how we can plot the mean. Assume, we are curious to know how successful movies are in each of the genres. The mean could be a good starting point to answer this question, because it provides the ‘average’ success of movies in a genre. The simplest approach to investigate this is to use a bar plot, like in Chapter 8.1. We first create a tibble that contains the means of gross_in_m for each genre in genre_01. Then we use this table to plot a bar plot with geom_col(). imdb_top_250 %&gt;% # Group data by genre group_by(genre_01) %&gt;% # Compute the mean for each group (remove NAs via na.rm = TRUE) summarise(mean_earnings_in_m = mean(gross_in_m, na.rm = TRUE)) %&gt;% # Create the plot ggplot(aes(x = genre_01, y = mean_earnings_in_m)) + geom_col() + coord_flip() It appears as if Action and Animation are far ahead of the rest. On average, both make around 200 million per movie. Adventure ranks third with only around 70 million. We can retrieve the exact earnings by removing the plot from the above code. imdb_top_250 %&gt;% group_by(genre_01) %&gt;% summarise(mean_earnings_in_m = mean(gross_in_m, na.rm = TRUE)) %&gt;% arrange(desc(mean_earnings_in_m)) ## # A tibble: 11 × 2 ## genre_01 mean_earnings_in_m ## &lt;fct&gt; &lt;dbl&gt; ## 1 Action 203. ## 2 Animation 189. ## 3 Adventure 73.9 ## 4 Biography 57.9 ## 5 Drama 52.9 ## 6 Crime 49.6 ## 7 Mystery 48.4 ## 8 Horror 41.6 ## 9 Comedy 33.2 ## 10 Western 8.81 ## 11 Film-Noir 0.45 In the last line I used a new function called arrange(). It allows us to sort rows in our dataset by a specified variable (i.e. a column). By default, arrange() sorts values in ascending order, which would put the top genre last. Therefore, we have to use another function to change the order to descending with desc(). Now the top genre is listed at the top. Based on this result we might believe that Action and Animation movies are the most successful genres. However, we have not taken into account how many movies there are in each genre. Consider the following example: # Assume there are 2 Action movies in the top 250 2 * 203 ## [1] 406 # Assume there are 10 Drama movies in the top 250 10 * 53 ## [1] 530 Thus, the ‘mean’ alone might not be a sufficient indicator. It can tells us which genre is most successful based on a single movie, but we also should consider how many movies there are in each genre. Let’s add the number of movies (n) in each genre to our table. imdb_top_250 %&gt;% group_by(genre_01) %&gt;% summarise(mean_earnings_in_m = mean(gross_in_m, na.rm = TRUE), n = n()) %&gt;% arrange(desc(mean_earnings_in_m)) ## # A tibble: 11 × 3 ## genre_01 mean_earnings_in_m n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Action 203. 40 ## 2 Animation 189. 24 ## 3 Adventure 73.9 20 ## 4 Biography 57.9 22 ## 5 Drama 52.9 72 ## 6 Crime 49.6 38 ## 7 Mystery 48.4 4 ## 8 Horror 41.6 3 ## 9 Comedy 33.2 23 ## 10 Western 8.81 3 ## 11 Film-Noir 0.45 1 Our interpretation might slighlty change based on these findings. There are considerably more movies in the genre Drama then in Action or Animation. We already plotted the frequency of movies per genre in Chapter 8.1. Accordingly, we would have to think that Drama turns out to be the most successful genre. As a final step, we can plot the sum of all earnings per genre as yet another indicator for the ‘most successful genre.’ imdb_top_250 %&gt;% filter(!is.na(gross_in_m)) %&gt;% group_by(genre_01) %&gt;% summarise(sum_gross_in_m = sum(gross_in_m)) %&gt;% ggplot(aes(x = genre_01, y = sum_gross_in_m)) + geom_col() + coord_flip() Theses results confirm that the Action genre made the most money out of all genres covered by the top 250 IMDb movies. I am sure you are curious to know which action movie contributed the most to this result. We can achieve this easily by using functions we already know. imdb_top_250 %&gt;% select(title, genre_01, gross_in_m) %&gt;% filter(genre_01 == &quot;Action&quot;) %&gt;% arrange(desc(gross_in_m)) %&gt;% top_n(5) ## Selecting by gross_in_m ## # A tibble: 5 × 3 ## title genre_01 gross_in_m ## &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Avengers: Endgame Action 858. ## 2 Avengers: Infinity War Action 679. ## 3 The Dark Knight Action 535. ## 4 The Dark Knight Rises Action 448. ## 5 Jurassic Park Action 402. Avengers: Endgame and Avengers: Infinity war rank the highest out of all Action movies. Two amazing movies if you are into Marvel comics. In the last line I sneaked in another new function from dplyr called top_n(). This function allows us to pick any given number of rows from the top. If you have many rows in your dataset (remember there are 40 action movies), you might want to be ‘picky’ and report only the top 3, 4 or 5. In conclusion, the mean is helpful in understanding how each individual movie on average performed across different genres. However, the mean alone provides a rather incomplete picture. Thus, we need always look at means in context of other information we have to gain a more comprehensive insight into our data. 8.2.2 Median The ‘median’ is the little, lesser known and used brother of the ‘mean.’ However, it can be a very powerful indicator for central tendency, because it is not so much affected by outliers. With outliers I mean observations that lie way beyond or below the average observation in our dataset. Let’s inspect the Action genre more closely and see how each movie in this category performed relative to each other. We first filter() our dataset to only show movies in the genre Action and also remove responses that have no value for gross_in_m. imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; &amp; !is.na(gross_in_m)) %&gt;% ggplot(aes(x = reorder(title, gross_in_m), y = gross_in_m)) + geom_col() + coord_flip() Avengers: Endgame and Avengers: Infinity War are far ahead of any other movie. We can compute the mean with and without these two movies. # Mean earnings for Action genre with Avengers movies imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot;) %&gt;% summarise(mean = mean(gross_in_m, na.rm = TRUE)) ## # A tibble: 1 × 1 ## mean ## &lt;dbl&gt; ## 1 203. # Mean earnings for Action genre with Avengers movies imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; &amp; title != &quot;Avengers: Endgame&quot; &amp; title != &quot;Avengers: Infinity War&quot;) %&gt;% summarise(mean = mean(gross_in_m, na.rm = TRUE)) ## # A tibble: 1 × 1 ## mean ## &lt;dbl&gt; ## 1 170. The result is striking. Without these two movies, the Action genre would have less earning per movie than the Animiation genre. However, if we computed the median instead, we would not notice such a huge difference in results. This is due to the fact that the median sorts a dataset, e.g. by gross_in_m and then picks the value that would cut the data into two equally large halves. It does not matter which value is the highest or lowest in our dataset, what matters is the value that is ranked right in the middle of all values. # Median earnings for Action genre with Avengers movies imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot;) %&gt;% summarise(median = median(gross_in_m, na.rm = TRUE)) ## # A tibble: 1 × 1 ## median ## &lt;dbl&gt; ## 1 180. # Median earnings for Action genre with Avengers movies imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; &amp; title != &quot;Avengers: Endgame&quot; &amp; title != &quot;Avengers: Infinity War&quot;) %&gt;% summarise(median = median(gross_in_m, na.rm = TRUE)) ## # A tibble: 1 × 1 ## median ## &lt;dbl&gt; ## 1 163. Both medians are much closer to each other, showing how much better suited the median is in our case. In general, when we report means, it is advisable to report the median as well. If a mean and median differ substantially, it could mean your data ‘suffers’ from outliers. So we have to detect them and think about whether we should remove them for further analysis. We can visualise medians using boxplots. Boxplots are a very effective tool to show how your data is distributed in one single data visualisation and it shows more than just the mean. It also shows the spread of your data (see Chapter @ref()). imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; &amp; !is.na(gross_in_m)) %&gt;% ggplot(aes(gross_in_m)) + geom_boxplot() To interpret this boxplot consider the Figure ??. [insert boxplot explanation figure here] The boxplot shows that we have apparently one observation that is an outlier, which is likely Avengers: Endgame, but what happened to the over Avengers movie? Is it no an outlier too? It seems we need some more information. We can overlay another geom_ on top to visualise where exactly each movie lies on this boxplot. We can represent each movie as a point by using geom_point(). This function requires us to define the values for the x and y axis. Here it makes sense to set y = 0 which aligns all the dots in the middle of the boxplot. imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; &amp; !is.na(gross_in_m)) %&gt;% ggplot(aes(gross_in_m)) + geom_boxplot() + geom_point(aes(y = 0, colour = &quot;red&quot;), show.legend = FALSE) To make the dots stand out more I changed the colour to \"red\". By adding the colour (color also works) attribute ggplot would automatically generate a legend. Since we do not need it we can specify it directly in the geom_point() function. If you prefer the legend, just remove show.legend = FALSE. The two dots on the right are the two Avengers movies. This plot also nicely demonstrates why boxplots are so popular and helpful: They provide so many insights, not only into the central tendency of a variable, but also highlights outliers and, more generally, gives a sense of the spread of our data (more about this in Chapter @ref()). The median is an important descriptive and diagnostic statistic and should be included in most empirical quantitative studies. 8.2.3 Mode Finally, the ‘mode,’ indicates which value is the most frequently occurring value for a certain variable. For example, we might be interested in knowing which IMDb rating was most frequently awarded to the top 250 movies. When trying to compute the mode in R, we quickly run into a problem, because there is no function available to do this straight away unless you search for a package that does it for you. However, before you start searching, let’s reflect on what the mode does and why we can find out the mode without additional packages or functions. The mode is based on the frequency of the occurrence of a value. Thus, the most frequently occurring value would be the one that is listed at the top of a frequency table. We have already created several frequency tables in this book and we can create another one to find the answer to our question. imdb_top_250 %&gt;% count(imdb_rating) ## # A tibble: 12 × 2 ## imdb_rating n ## &lt;dbl&gt; &lt;int&gt; ## 1 8.1 80 ## 2 8.2 45 ## 3 8.3 42 ## 4 8.4 29 ## 5 8.5 22 ## 6 8.6 14 ## 7 8.7 5 ## 8 8.8 5 ## 9 8.9 3 ## 10 9 3 ## 11 9.2 1 ## 12 9.3 1 We can also easily visualise this frequency table in the same way as before. In order to make the plot a bit more ‘fancy,’ we can add labels to the bar which reflect the frequency of the rating. We need to add the attribute label and also add a geom_text() layer to display them. Because the numbers would overlap with the bars, I ‘nudge’ the labels up by 4 units on the y axis. imdb_top_250 %&gt;% count(imdb_rating) %&gt;% ggplot(aes(imdb_rating, n, label = n)) + geom_col() + geom_text(nudge_y = 4) The frequency table and the plot reveal that the mode for imdb_rating is 8.1. In addition, we also get to know how often this rating was applied, i.e. 80 times. This provides much more information then receiving a single score and helps to better interpret the importance of the mode as an indicator for central tendency. Consequently, there is generally no need to compute the mode if you can have a frequency table instead. Still, if you are keen to have a function that computes the mode, you will have to write your own function, e.g. as shown in this post on stackeroverflow.com or search for a package that coded one already. As a final remark, it is also possible that you can find two or more modes in your data. For example, if the rating 8.1 appears 80 times and the rating 9.0 appears 80 times, both would be considered to a mode. 8.3 Indicators and visualisations to examine the spread of data Understanding how your data is spread out is important to get a better sense of what your data is composed of. We already touched upon the notion of spread in Chapter 8.2.2 through plotting a boxplot. The spread of data provides insights into how homogeneous or heterogeneous the responses of our participants are. In the following we will cover some essential techniques to investigate the spread of your data and investigate whether our variables are normally distributed, which is often an important assumption for certain analytical techniques. In addition, we will aim to identify outliers which could be detrimental to subsequent analysis and significantly affect our modelling and testing in later stages. 8.3.0.1 Boxplot: So much information in just one box The boxplot is a staple in visualising descriptive statistics. If offers so much information in just a single plot that it might not take much to convince you that it has become a very popular way to show the spread of data. For example, we might be interested to know how long most movies run. Our gut feeling might tell us that most movies are probably around 2 hours long. One approach to find out is a boxplot, which we used before. imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_boxplot() + annotate(&quot;text&quot;, label = &quot;Gangs of Wasseypur \\n (321 min)&quot;, x = 310, y = 0.05, size = 2.5) + annotate(&quot;text&quot;, label = &quot;Sherlock Jr. \\n (45 min)&quot;, x = 45, y = 0.05, size = 2.5) Figure 8.1: A boxplot The results indicate that most movies are between 100 to 150 minutes long. Our intuition was right. We find that one movie is even over 300 minutes long, i.e. over 5 hours: ‘Gangs of Wasseypur.’ In contrast, the shortest movie only lasts 45 minutes and is called ‘Sherlock Jr.’ I added annotations using annotate() to highlight these two movies in the plot. Both movies would also count as outliers in our dataset (see Chapter 8.3.3.2. 8.3.0.2 Histogram: Do not mistake it as a bar plot Another frequently used approach to show the spread (or distribution) of data is the histogram. The histogram easily gets confused with a bar plot. However, you would be very mistaken to assume that they are the same. Some key differences between these two types of plots is summarised in Table 8.1. Table 8.1: Histogram vs bar plot Histogram Bar plot Used to show the distribution of non-categorical data Used for showing the frequency of categorical data, i.e. factors Each bar (also called ‘bin’) represents a group of observations. Each bar represents one category (or level) in our factor. The order of the bars is important and cannot/should not be changed. The order of bars is arbitrary and can be reordered if meaningful. To make this difference even clearer, let’s overlap a bar plot with a histogram for the same variable. imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram() + geom_bar(aes(fill = &quot;red&quot;), show.legend = FALSE) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. There are a couple of important observations to be made: The bar plot has much shorter bars, because each bar represents the frequency of a single unique score. Thus, the runtime of 151 is represented as a bar as is the runtime of 152. Only identical observations are grouped together. As such, the bar plot is based on a frequency table, similar to what we computed before. In contrast, the histogram’s ‘bars’ are higher because they group together individual observations based on a specified range, e.g. one bar might represent movies that have a runtime between 150-170 minutes. These ranges are commonly called bins. We can control the number of bars in our histogram using the bins attribute. ggplot even reminds us in a warning that we should adjust it to represent more details in the plot. Let’s experiment with this setting to see how it would look like with different numbers of bins. imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram(bins = 5) + geom_bar(aes(fill = &quot;red&quot;), show.legend = FALSE) imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram(bins = 20) + geom_bar(aes(fill = &quot;red&quot;), show.legend = FALSE) imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram(bins = 60) + geom_bar(aes(fill = &quot;red&quot;), show.legend = FALSE) imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram(bins = 300) + geom_bar(aes(fill = &quot;red&quot;), show.legend = FALSE) As becomes obvious, if we select a large enough number of bins, we can achieve the same result as a bar plot. This is the closest a bar plot can become to a histogram, i.e. if you define the number of bins in such a way that each observation is captured by one bin. While theoretically possible, practically this rarely makes much sense. We use histograms to judge whether our data is normally distributed. A normal distribution is often a requirement for assessing whether we can run certain types of analyses or not. In short: It is very important to know about it in advance. The shape of a normal distribution looks like a bell (see Figure 8.2). If our data is equal to a normal distribution we find that the mean and the median are the same value, and can conclude that the mean is a good representation for our data/variable. Figure 8.2: A normal distribution Let’s see whether our data is normally distributed using the histogram we already plotted and overlay a normal distribution. The coding for the normal distribution is a little more advanced. Do not worry if you cannot fully decipher its meaning just yet. To draw such a reference plot we need to: compute the mean() of our variable, compute the standard deviation sd() of our variable (see Chapter 8.3.2, use the function geom_func() to plot it and, define the function fun as dnorm, which stands for ‘normal distribution.’ More important than understanding how the computational side works, is the aim of this task: we try to compare our distribution with a normal one. imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_histogram(aes(y = ..density..), bins = 30) + # This part creates a normal curve based on the mean # and standard deviation of our data geom_function(fun = dnorm, n = 103, args = list(mean = mean(imdb_top_250$runtime_min), sd = sd(imdb_top_250$runtime_min)), colour = &quot;red&quot;) However, there are two problems if we use histograms in combination with a normal distribution reference plot: First, the y axis needs to be transformed to fit the normal distribution (which is a density plot and not a histogram). Second, the shape of our histogram is affected by the number of bins we have chosen, which is an arbitrary choice we make. Besides, the lines of code might be tough to understand, because we have to ‘hack’ the visualisation to make it work. There is, however, a better way to do this: Density plots. 8.3.0.3 Density plots: Your smooth histograms Density plots are a special form of the histogram. It uses ‘kernel smoothing,’ which turns our blocks into a smoother shape. Better than trying to explain what it does, it might help to see it. We use the same data but replace geom_histogram() with geom_density(). # Ingredients for our normality reference plot mean_ref &lt;- mean(imdb_top_250$runtime_min) sd_ref &lt;- sd(imdb_top_250$runtime_min) imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_density() + geom_function(fun = dnorm, n = 103, args = list(mean = mean_ref, sd = sd_ref), colour = &quot;red&quot;) Figure 8.3: Density plot vs normal distribution For density plots we can aslo define how big the bins are which make the plot more or less smooth. After all, the density plot is a histogram, but the transitions from one bin to the next are ‘smoothed.’ Here is an example of how different bw settings affect the plot. # Ingredients for our normality reference plot mean_ref &lt;- mean(imdb_top_250$runtime_min) sd_ref &lt;- sd(imdb_top_250$runtime_min) # bw = 18 imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_density(bw=18) + geom_function(fun = dnorm, n = 103, args = list(mean = mean_ref, sd = sd_ref), colour = &quot;red&quot;) + ggtitle(&quot;bw = 18&quot;) # bw = 3 imdb_top_250 %&gt;% ggplot(aes(runtime_min)) + geom_density(bw=3) + geom_function(fun = dnorm, n = 103, args = list(mean = mean_ref, sd = sd_ref), colour = &quot;red&quot;) + ggtitle(&quot;bw = 18&quot;) The benefits of the density plot in this situation are obvious: It is much easier to see whether our data is normally distributed or not when compared to a reference plot. However, we still might struggle to determine normality just by these plots, because it depends on how high or low we set bw. Luckily, there is also a statistical method to test whether our data is normally distributed: The Shapiro-Wilk test. This test compares our distribution with a normal distribution (like in our plot) and tells us whether our distribution is significantly different from it. Thus, if the test is not significant the distribution of our data is not significantly different from a normal distribution, or in simple terms: It is normally distributed. We can run the test in R as follows: shapiro.test(imdb_top_250$runtime_min) ## ## Shapiro-Wilk normality test ## ## data: imdb_top_250$runtime_min ## W = 0.92436, p-value = 5.544e-10 According to this result, we have to accept that our data is not normally distributed, because it is significantly different from it (p&lt;0.05). We look at significance and its meaning more thoroughly in the next chapter (Chapter 9). 8.3.0.4 Violin plot: Your smooth boxplot If a density plot is the sibling of a histogram, the violin plot would be the sibling of a boxplot, but the twin of a density plot. Confused? If so, then let’s use the function geom_volin() to create one. imdb_top_250 %&gt;% ggplot(aes(x = runtime_min, y = 0)) + geom_violin() Looking at our plot it becomes evident where the violin plot got its name from, i.e. its shape. The reason why it also a twin of the density plot becomes clear when we only plot half of the violin. imdb_top_250 %&gt;% ggplot(aes(x = 0, y = runtime_min)) + see::geom_violinhalf()+ coord_flip() ## Registered S3 methods overwritten by &#39;parameters&#39;: ## method from ## as.double.parameters_kurtosis datawizard ## as.double.parameters_skewness datawizard ## as.double.parameters_smoothness datawizard ## as.numeric.parameters_kurtosis datawizard ## as.numeric.parameters_skewness datawizard ## as.numeric.parameters_smoothness datawizard ## print.parameters_distribution datawizard ## print.parameters_kurtosis datawizard ## print.parameters_skewness datawizard ## summary.parameters_kurtosis datawizard ## summary.parameters_skewness datawizard It looks exactly like the density plot we plotted earlier (see Figure 8.3. The interpretation largely remains the same to a density plot as well. The relationship between the boxplot and the violin plot lies in the symmetry of the violin plot. At this point, it is fair to say that we enter ‘fashion’ territory. It is really up to your taste which visualisation you prefer, because they are largely similar, but offer nuances that some data sets might require. Lastly, I cannot finish this chapter without sharing with you one of the most popular uses of half-violin plots: The rain cloud plot. It is a combination of a dot plot with a density plot. Each dot represents a movie in our dataset. This creates the appearance of a cloud with rain drops. There are several packages available that can create such a plot. Here I used the see package. imdb_top_250 %&gt;% filter(genre_01 == &quot;Action&quot; | genre_01 == &quot;Drama&quot;) %&gt;% ggplot(aes(x = genre_01, y = imdb_rating, fill = genre_01)) + see::geom_violindot(fill_dots = &quot;blue&quot;, size_dots = 0.2) + see::theme_modern() + coord_flip() 8.3.1 QQ plot: A ‘cute’ plot to check for normality in your data The QQ plot is an alternative to comparing distributions to a normality curve. Instead of a curve, we plot a line which represents the quantiles of our data against the quantiles of a normal distribution. The term ‘quantile’ can be somewhat confusing, especially after learning about the boxplot, which shows quartiles. There is a relationship between these terms. Consider the following comparison: \\(1^{st}\\) Quartile = \\(25^{th}\\) percentile = 0.25 quantile \\(2^{nd}\\) Quartile = \\(50^{th}\\) percentile = 0.50 quantile = median \\(3^{rd}\\) Quartile = \\(75^{th}\\) percentile = 0.75 quantile With these definitions out of the way, let’s plot some quantiles against each other. imdb_top_250 %&gt;% ggplot(aes(sample = runtime_min)) + geom_qq() + geom_qq_line(colour = &quot;red&quot;)+ annotate(&quot;text&quot;, label = &quot;The 5h long movie&quot;, x = 2.5, y = 308, size = 3) The function geom_qq() is responsible for creating the dots, while geom_qq_line creates a reference for a normal distribution. The reference line is drawn in such a way that it touches the quartiles of our distribution. Ideally, we would want that all dotes are firmly aligned with each other. Unfortunately, this is not the case in our dataset. At the top and at the bottom we have points that deviate quite far from a normal distribution. Remember the five hour long movie? It is very far away from the rest of the other movies in our dataset. 8.3.2 Standard deviation: Your average deviation from the mean I left the most commonly reported statistics for the spread of data last. The main reasons for this lies in the fact that one easily jumps ahead to look at the standard deviation without ever considering plotting the distribution in the first place. Similar to the mean and other numeric indicators, they could potentially convey the wrong impression. Nevertheless, the standard deviation is an import measure. To understand what the standard deviation is, we can consider the following visualisation: runtime_mean &lt;- mean(imdb_top_250$runtime_min) imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = title, y = runtime_min)) + geom_point() + geom_hline(aes(yintercept = runtime_mean, colour = &quot;red&quot;), show.legend = FALSE) + # Making the plot a bit more pretty theme(axis.text.x = element_blank(), # Removes movie titles panel.grid.major = element_blank(), # Removes grid lines panel.background = element_blank() # Turns background white ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) The red line represent the mean runtime for all movies in the dataset, which is 129 minutes. We notice that the points are falling around the mean, but not really directly on it. In other words, there are not many movies that are about 129 minutes long. We make this visualisation even more meaningful if we sorted the movies by their runtime. We can also change the shape of the dots (see also Chapter 9 by using the attribute shape. This helps to plot many dots without having them overlap. imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) + geom_point(shape = 124) + geom_hline(aes(yintercept = runtime_mean, colour = &quot;red&quot;), show.legend = FALSE) + theme(axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank() ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) As we can see, there is only a small fraction of movies that are close to the mean. If we now consider the distance of each dot from the red line, we know how much each dot, i.e. each movie, deviates from the mean. The standard deviation tells us how much the runtime deviates on average. To be more specific, to compute the standard deviation by hand you would: subtract the mean runtime from the runtime of each movie and square it, i.e. \\(deviations = (runtime\\_min - mean_{all\\ movies})^2\\), then we take the sum of all deviations and divide it by the number of movies minus 1, i.e. \\(\\frac{\\sum(deviations)}{250-1}\\), and because we squared the deviations, we take the square root of this score, i.e. \\(\\sqrt{\\frac{\\sum(deviations)}{250-1}}\\). We could compute this by hand if we wanted, but it is much simpler to use the functionsd() to achieve the same. The result shows that movies tend to be about 32 minutes longer or shorter than the average movie. This seems quite long. sd(imdb_top_250$runtime_min) ## [1] 32.63701 However, we have to be aware that this score is also influenced by the outliers we detected before. As such, if standard deviations in your data appear quite large, it likely is due to outliers and you should investigate further. Needless to say, plotting your data will undoubtedly help to diagnose any outliers. 8.3.3 Dealing with outliers In this Chapter, I referred to outliers many times but never eluded to the aspects of handling them. Dealing with outliers is similar to dealing with missing data. It is not quite as straightforward as one might think. In a first step, we need to determine which values count as an outlier. Aguinis, Gottfredson, and Joo (2013) reviewed 232 journal articles and found that scholars had defined outliers in 14 different ways, used 39 different techniques to detect them and applied 20 different strategies to handle them. It would be impossible to work through all different options in this book. However, I want to offer two options that have been frequently considered in publications in the field of Social Sciences: the standard deviation the inter-quartile range 8.3.3.1 Detecting outliers using the standard deviation A very frequently used approach to detecting outliers is the use of the standard deviation. Usually, scholars use multiples of the standard deviation to determine thresholds. For example, a value that lies 3 standard deviations above or below the mean could be categorised as an outlier. Unfortunately, there is quite some variability regarding how many multiples of the standard deviation counts as an outlier. Some authors might use 3, others might settle for 2 (see also Leys et al. (2013)). Let’s stick with the definition of 3 standard deviations to begin with. We can revisit our previous plot and add lines which show the thresholds above and below the mean. # Compute the mean and standard deviation runtime_mean &lt;- mean(imdb_top_250$runtime_min) sd_upper &lt;- runtime_mean + 3 * sd(imdb_top_250$runtime_min) sd_lower &lt;- runtime_mean - 3 * sd(imdb_top_250$runtime_min) # Create our plot imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) + geom_point(shape = 124) + geom_hline(aes(yintercept = runtime_mean, colour = &quot;red&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = sd_upper, color = &quot;blue&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = sd_lower, color = &quot;blue&quot;), show.legend = FALSE) + theme(axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank() ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) The results suggests that only very few outliers would be detected if we chose these thresholds. Especially ‘Sherlock Jr.’ the shortest movie in our dataset would not classify as an outlier. How about we choosen two standard deviations instead? # Compute the mean and standard deviation runtime_mean &lt;- mean(imdb_top_250$runtime_min) sd_upper &lt;- runtime_mean + 2 * sd(imdb_top_250$runtime_min) d_lower &lt;- runtime_mean - 2 * sd(imdb_top_250$runtime_min) # Create our plot imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) + geom_point(shape = 124) + geom_hline(aes(yintercept = runtime_mean, colour = &quot;red&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = sd_upper, color = &quot;blue&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = sd_lower, color = &quot;blue&quot;), show.legend = FALSE) + theme(axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank() ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) As we would expect, we identify some more movies as being outliers. Still, it feels rather arbitrary to choose a threshold of our liking. Despite its popularity, there are additional problems with this approach: outliers affect our mean and standard deviation too, since we use the mean, we assume that our data is normally distributed, and in smaller samples, this approach might result in not identifying outliers at all (despite their presence) (Leys et al. (2013), p. 764) Leys et al. (2013) propose an alternative approach, based on the fact that medians are much less vulnerable to outliers than the mean. Similarly to the standard deviation, it is possible to calculate thresholds using the ‘median absolute deviation’ (MAD). Best of all, the function mad() in R does this automatically for us. Leys et al. (2013) suggest to use 2.5 times the MAD as a threshold. However, if we want to compare directly how well this option does against the standard deviation, we should 3 again. # Compute the median and thresholds runtime_median &lt;- median(imdb_top_250$runtime_min) mad_upper &lt;- runtime_median + 3 * mad(imdb_top_250$runtime_min) mad_lower &lt;- runtime_median - 3 * mad(imdb_top_250$runtime_min) # Create our plot imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) + geom_point(shape = 124) + geom_hline(aes(yintercept = runtime_median, colour = &quot;red&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = mad_upper, color = &quot;blue&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = mad_lower, color = &quot;blue&quot;), show.legend = FALSE) + theme(axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank() ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) Compared to our previous results, we notice that the median approach was much better in detecting outliers at the upper range of runtim_min. Because the median is not affected so much by the five hour-long movie, the results have improved. Still, we would not classify the outlier at the bottom for the shortest movie in the data. If we chose the criterion of 2.5*MAD, we would also get this outlier (see Figure 8.4). Figure 8.4: Outlier detection via MAD using 2.5 * MAD as a threshold Which approach to choose can be informed by the normality of your data. If your data is normally distributed, the mean and median would be very close to each other and the results from both approach would return very similar results. However, if your data is not normally distributed, it might be better to classify outliers using the median. 8.3.3.2 Detecting outliers using the interquartile range Another approach to classify outliers is the use of the interquartile range (IQR). This one is used in boxplots and creates the dots at its ends to indicate any outliers. This approach is very easy to implement because the computation of the IQR is simple: \\(IQR = Q_{3}-Q_{1}\\) Therefore, we can create new thresholds for the detection of outliers. For IQR it is common to use ‘1.5 * IQR’ as the lower and upper thresholds. # Compute the median and thresholds runtime_median &lt;- median(imdb_top_250$runtime_min) iqr_upper &lt;- runtime_median + 1.5 * IQR(imdb_top_250$runtime_min) iqr_lower &lt;- runtime_median - 1.5 * IQR(imdb_top_250$runtime_min) # Create our plot imdb_top_250 %&gt;% select(title, runtime_min) %&gt;% ggplot(aes(x = reorder(title, runtime_min), y = runtime_min)) + geom_point(shape = 124) + geom_hline(aes(yintercept = runtime_median, colour = &quot;red&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = iqr_upper, color = &quot;blue&quot;), show.legend = FALSE) + geom_hline(aes(yintercept = iqr_lower, color = &quot;blue&quot;), show.legend = FALSE) + theme(axis.text.x = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank() ) + ylab(&quot;run time&quot;) + xlab(&quot;movies&quot;) As we can tell, the IQR detects much more outliers for our data than any of the previous methods. The outliers we find here are the same as shown in Figure 8.1. For our data it seems that the MAD by Leys et al. (2013) produced the ‘best’ selection. However, we have to acknowledge that these classifications will always be subjective, because the decision of how we position the thresholds is still depending on the researcher’s choice. 8.3.3.3 Removing or replacing outliers Now that we have identified our outliers we are confronted with the question what we should do with them. Similar to missing data (see Chapter 7.6) we can either remove them or replace them with other values. While removal is a fairly simple task, replacing it with other ‘reasonable’ values implies that we need to find techniques to create such values. As you may remember, we were confronted with a similar problem before when we looked into missing data (Chapter 7.6. The same techniques, especially multiple imputation (see Cousineau and Chartier 2010), can be used for such scenarios as well. Irrespective of whether we remove or replace outliers, we somehow need to single them out of the crowd. Since the MAD strategy worked well for our data, we can use the thresholds we defined before, i.e. mad_upper and mad_lower. Therefore, an observation (i.e. a movie) is considered as an outlier if: its value lies above mad_upper, or its value lies below mad_lower It becomes clear that we somehow need to define a condition, because if it is an outlier, it should be labelled as one, if not then it should not be labelled as one. Ideally we want a new column in our dataset which indicates whether a movie is an outlier (i.e. outlier = TRUE) or not (outlier = FALSE). R offers a way for us to express such conditions with the function ifelse(). It has the following structure: ifelse(condition, TRUE, FALSE) Let’s formulate a sentence that describes our scenario as an ifelse() function: If a movie’s runtime_min is longer than mad_upper, or if a movie’s runtime_min is lower than mad_lower, classify this movie as an outlier (i.e. TRUE), otherwise classify this movie as not being an outlier (i.e. FALSE). We already know from Chapter 5.1 how to use logical and arithmetic operators. All we have to do is put them together in one function call. imdb_top_250 &lt;- imdb_top_250 %&gt;% mutate(outlier = ifelse(runtime_min &gt; mad_upper | runtime_min &lt; mad_lower, TRUE, FALSE)) Since we have a classification we can more thoroughly inspect our outliers and see which movies are the ones that are lying outside our defined norm. We can arrange() them by runtime_min. imdb_top_250 %&gt;% filter(outlier == &quot;TRUE&quot;) %&gt;% select(title, runtime_min, outlier) %&gt;% arrange(runtime_min) ## # A tibble: 10 × 3 ## title runtime_min outlier ## &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 Sherlock Jr. 45 TRUE ## 2 The Lord of the Rings: The Return of the King 201 TRUE ## 3 The Godfather: Part II 202 TRUE ## 4 Andrei Rublev 205 TRUE ## 5 Seven Samurai 207 TRUE ## 6 Ben-Hur 212 TRUE ## 7 Lawrence of Arabia 228 TRUE ## 8 Once Upon a Time in America 229 TRUE ## 9 Gone with the Wind 238 TRUE ## 10 Gangs of Wasseypur 321 TRUE The list of movies contains some of the most iconic Hollywood films ever shown on screen. I think we can agree that most of them are truly outside the norm of regular movies, not just in terms of runtime. From here it is simple to remove these movies (i.e. keep the movies that are not outliers) or set their values to NA by writing the following lines of code. We replace the values with NA we can the continue with one of the techniques demonstrated for missing values (Chapter 7.6. # Keep all movies that are not outliers imdb_top_250 %&gt;% filter(outlier == &quot;FALSE&quot;) # Replace values with NA imdb_top_250 %&gt;% mutate(runtime_min = replace(runtime_min, outlier == &quot;TRUE&quot;, NA)) The replace() function is very intuitive to use. It first needs to know where you want to replace a value (runtime_min), then what the condition for replacing is (outlier == \"TRUE\"), and lastly, which value should be put instead of the original one (NA). As you hopefully noticed, understanding your data requires some effort, but it is important to know your data well before proceeding to any further analysis. You can experiment with different data visualisations and design them in a way that best reflect the message you want to get across. For example, because we have now a separate variable which classifies outliers we can do more with our data visualisation than before and dress it up a bit more nicely. colour_pal &lt;- wesanderson::wes_palette(&quot;Darjeeling1&quot;, 11, type = &quot;continuous&quot;) imdb_top_250 %&gt;% ggplot(aes(x = reorder(genre_01, runtime_min), y = runtime_min, colour = genre_01) ) + geom_boxplot(alpha = 0, show.legend = FALSE) + geom_jitter(width = 0.1, size = 0.5, alpha = 0.5, show.legend = FALSE) + scale_color_manual(values = colour_pal) + coord_flip() + theme(panel.background = element_blank())+ xlab(&quot;runtime&quot;) + ylab(&quot;Genre&quot;) + ggtitle(&quot;Distribution of movie runtimes by genre&quot;) References "]]
