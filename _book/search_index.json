[["comparing-groups.html", "12 Comparing groups 12.1 Comparability: Apples vs Oranges 12.2 Comparing two groups 12.3 Comparing more than two groups 12.4 Comparing groups based on factors: Contingency tables 12.5 A cheatsheet to guide your own group comparisons", " 12 Comparing groups ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.4 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() ## ## Attaching package: &#39;rstatix&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## Rows: 69578 Columns: 6 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (3): country, gender, relationship_status ## dbl (3): age, freedom_of_choice, satisfaction ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Social Sciences is about the study of human beings and their interactions. As such, we frequently want to compare two or more groups of human beings, organisations, teams, countries, etc., with each other to see whether they are similar or different from each other. Sometimes we also want to track individuals over time and see how they may have changed in some way or other. In short, comparing groups is an essential technique to make inferences and helps us better understand the diversity that surrounds us. If we want to perform a group comparison we have to consider which technique is most appropriate for the data we have. Some of it might be related to the type of data we have collected, other aspects might be linked to the distribution of the data. More specifically, before we apply any statistical technique we have to consider at least the following: missing data (see Chapter 7.6), outliers (see Chapter 9.5, and the assumptions made by analytical techniques about our data. While we covered missing data and outliers in previous chapters, we have yet to discuss assumptions. For group comparisons there are three main questions we need to answer: Are the groups big enough to be compared, i.e. are they comparable? Is my data parametric or non-parametric? (see Chapter ??) How many groups do I wish to compare? Are these groups paired or unpaired? In the following we will look at group comparisons for parametric and non-parametric data in each category and use the wvs_nona dataset, i.e. the wvs data frame after we performed imputation (see also Chapter 7.6.3). Since we already covered how to test whether data is parametric or non-parametric we will forgo this step out of pure convenience and to remain succinct. We also ignore any potential outliers or missing data. The case studies at the end of the book provide realistic examples of how to perform groups comparisons with a new set of data from start to finish (see Chapter @ref()). Thus, parametric and non-parametric tests will be demonstrated with the same dataset and the same variables. 12.1 Comparability: Apples vs Oranges Before we can jump into group comparisons we need to make ourselves aware of whether our groups can be compared in the first place. ‘Comparability’ should not be confused with ‘are the groups equal.’ In many cases, we don’t want groups to be equal in terms of participants, e.g. between-subject studies. On the other hand, we might want groups to be perfectly equal when we perform within-subject studies. Thus, asking whether groups are comparable is unrelated to whether the subjects in our study are the same. Instead, we are looking at characteristics of our groups. Some commonly considered characteristics include: size: Are the groups about equally large? time: Was the data collected around the same time? exogenous variables: Is the distribution of characteristics we are not interested in, approximately the same across groups? When we compare groups we want to minimise the systematic differences that are not the primary focus of our study. Using the right sampling technique can help with this matter. For example, using a random sample and performing a random allocation to groups can help with achieving comparable groups and remove systematic differences in a way no other sampling strategy can. However, there is still no guarantuee that they will be comparable (see also Altman (1985) and Berger (2006)). Besides, we also face the challenge that in Social Sciences we do not have the option of random sampling. For example, International Business studies heavily rely on lists provided by others, e.g. the European Union, Fortune 500, etc., personal judgement and convenience sampling and only a small proportion actually perform probability sampling (Yang, Wang, and Su 2006). In short, there is no reason to worry if your sampling technique is not random to begin with. However, it emphasises the need to understand your sample and your groups thoroughly. In order to inspect characteristics of groups we wish to compare, we can use descriptive statistics as we covered them in Chapter 8. The only aspect that is different is that we apply these techniques to subsets of our data and not the entire dataset. For example, we might wish to compare female and male Egyptians (see Chapter 12.2.1). If we wanted to make sure these two groups can be compared we might have to check (among other characteristics) whether their age is distributed similarly. We can use the functions we already know to create a plot to investigate this matter. We could either use a boxplot, or, a bit more accurate, a density plot using the ggridges package. # Only select participants from &#39;Egypt&#39; comp &lt;- wvs_nona %&gt;% filter(country == &quot;Egypt&quot;) comp %&gt;% ggplot(aes(x = age, y = gender, fill = gender)) + ggridges::geom_density_ridges(bandwidth = 4) As we can see, the distribution of age across both gender groups is fairly similar and likely not different between groups. Of course, we could also statistically explore this using a suitable test before performing the main group comparison. However, we first have to understand how we can perform them. In the following chapters we will largely rely the package rstatix which offers a pipe-friendly approach to using the built-in functions to perform our group comparisons. However, you are welcome to also try the basic functions as well, which you can find in Chapter ??. 12.2 Comparing two groups The simplest of comparisons is the one where you only have two groups. These groups could either consist of different people (unpaired) or represent two measurements of the same individuals (paired). 12.2.1 Two Unpaired groups An unpaired group test assumes that the observations in each group are not related to each other, for example that the participants in each group are different individuals. Our first comparison will be participants from Egypt and we want to understand whether male and female citizens in this country perceive that they have freedom_of_choice. We first can compare these two groups using our trusty geom_boxplot (or any variation of it). # Compute the mean for and size of each group group_means &lt;- comp %&gt;% group_by(gender) %&gt;% summarise(g_mean = mean(freedom_of_choice), n = n()) group_means ## # A tibble: 2 × 3 ## gender g_mean n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 female 6.21 579 ## 2 male 6.82 621 # Create our data visualisation comp %&gt;% ggplot(aes(x = gender, y = freedom_of_choice, fill = gender)) + geom_boxplot() + # Add the mean for each group geom_point(data = group_means, aes(x = gender, y = g_mean), shape = 3, size = 2) While the distribution looks similar, we can notice that the median and the mean (marked by the cross inside the boxplot) are slighter higher for male participants. Thus, we can suspect slight differences between these two groups, but we do not know whether these differences are significant or not. To consider the significance (remember Chapter 10.3) and the effect size (see Table ??) we have to perform statistical tests. Table 12.1 summarises the different tests and functions to perform the group comparison computationally. It is important to note that the parametric test compares the means of two groups, while the non-parametric test compares medians. All of these tests turn significant if the differences between groups is large enough. Thus, significant results can be read as ‘these groups are significantly different from each other.’ Of course, if the difference is not significant, the groups are considered to be not different from each other. For parametric tests, i.e. t.test(), it is also important to indicate whether the variances between these two groups are equal or not. Remember this was one of the assumptions for parametric tests. The Welch t-test can be used if the variances are not equal, but all other criteria for normality are met. By setting var.equal = TRUE, a regular T-Test would be performed. By defaulty, t.test assumes that variances are not equal. Make sure you test for homogeneity of variance before making your decision (see Chapter 9.4. Table 12.1: Comparing two unpaired groups (effect size functions from package effectsize, except for wilcoxonR() from rcompanion Assumption Test Function Effect size Function Parametric T-Test Welch T-Test t_test(var.equal = TRUE) t_test(var.equal = FALSE) Cohen’s d cohens_d() Non-parametric Mann-Whitney U wilcox_test(paired = FALSE) Wilcoxon R wilcoxonR() With this information in hand, we can start comparing the female Egyptians with the male Egyptians using the parametric and the non-parametric test for illustration purposes only. By setting detailed = TRUE we can obtain the maximum amount for certain comparisons information. In such cases it is advisable to use glimpse(). This will make the output easier to read because each row presents one piece of information, rather than having one row with many columns. # T-Test comp %&gt;% t_test(freedom_of_choice ~ gender, var.equal = TRUE, detailed = TRUE) %&gt;% glimpse() ## Rows: 1 ## Columns: 15 ## $ estimate &lt;dbl&gt; -0.6120414 ## $ estimate1 &lt;dbl&gt; 6.212435 ## $ estimate2 &lt;dbl&gt; 6.824477 ## $ .y. &lt;chr&gt; &quot;freedom_of_choice&quot; ## $ group1 &lt;chr&gt; &quot;female&quot; ## $ group2 &lt;chr&gt; &quot;male&quot; ## $ n1 &lt;int&gt; 579 ## $ n2 &lt;int&gt; 621 ## $ statistic &lt;dbl&gt; -4.75515 ## $ p &lt;dbl&gt; 2.22e-06 ## $ df &lt;dbl&gt; 1198 ## $ conf.low &lt;dbl&gt; -0.864566 ## $ conf.high &lt;dbl&gt; -0.3595169 ## $ method &lt;chr&gt; &quot;T-test&quot; ## $ alternative &lt;chr&gt; &quot;two.sided&quot; # Welch t-test (var.equal = FALSE by default) comp %&gt;% t_test(freedom_of_choice ~ gender, var.equal = FALSE, detailed = TRUE) %&gt;% glimpse() ## Rows: 1 ## Columns: 15 ## $ estimate &lt;dbl&gt; -0.6120414 ## $ estimate1 &lt;dbl&gt; 6.212435 ## $ estimate2 &lt;dbl&gt; 6.824477 ## $ .y. &lt;chr&gt; &quot;freedom_of_choice&quot; ## $ group1 &lt;chr&gt; &quot;female&quot; ## $ group2 &lt;chr&gt; &quot;male&quot; ## $ n1 &lt;int&gt; 579 ## $ n2 &lt;int&gt; 621 ## $ statistic &lt;dbl&gt; -4.756287 ## $ p &lt;dbl&gt; 2.21e-06 ## $ df &lt;dbl&gt; 1193.222 ## $ conf.low &lt;dbl&gt; -0.8645067 ## $ conf.high &lt;dbl&gt; -0.3595762 ## $ method &lt;chr&gt; &quot;T-test&quot; ## $ alternative &lt;chr&gt; &quot;two.sided&quot; # Mann-Withney U test comp %&gt;% wilcox_test(freedom_of_choice ~ gender, detailed = TRUE) %&gt;% glimpse() ## Rows: 1 ## Columns: 12 ## $ estimate &lt;dbl&gt; -0.999948 ## $ .y. &lt;chr&gt; &quot;freedom_of_choice&quot; ## $ group1 &lt;chr&gt; &quot;female&quot; ## $ group2 &lt;chr&gt; &quot;male&quot; ## $ n1 &lt;int&gt; 579 ## $ n2 &lt;int&gt; 621 ## $ statistic &lt;dbl&gt; 149937.5 ## $ p &lt;dbl&gt; 4.97e-07 ## $ conf.low &lt;dbl&gt; -0.9999694 ## $ conf.high &lt;dbl&gt; -5.79946e-05 ## $ method &lt;chr&gt; &quot;Wilcoxon&quot; ## $ alternative &lt;chr&gt; &quot;two.sided&quot; You might notice that the notation within the functions for group tests looks somewhat different to what we are used to, i.e. we use the ~ (‘tilde’) symbol. Some functions take a formula as their attribute and to distinguish the dependent and independent variable from each other we use ~. A more generic notation of how formulas in functions work is shown below, where DV stands for dependent variable and IV stands for independent variable: function(formula = DV ~ IV) Group comparisons, even for multiple groups, we usually only have one independent variable, i.e. the grouping variable. Grouping variables are usually of the type factor. In case of two groups, we have two levels present in this factor, e.g. gender. If there are multiple groups, the factor contains multiple levels, e.g. country. No matter which test we run, it appears as if the difference is significant. However, how big is the difference? The answer to this is provided by the effect size. The interpretation of what the effect size is, follows the explanations in Chapter 10, where we looked at the strength of the correlation of two variables. However, different effect size measures imply that we have to use different benchmarks. To help us a bit with the interpretation we can use the effectsize package and their set of interpret_...() functions (see also Indices of Effect Size). Sometimes, there are even more than one way of computing the effect size. For example for the Mann-Whitney test we can choose between the classic Wilcoxon R or the rank-biserial correlation coefficient. In practice, you have to be explicit about how you computed the effect size. The differences between the two measures are often marginal and a matter of taste (or should I say: Your reviewers’ taste). Throughout this chapter I will rely on the effect sizes most commonly found in Social Sciences publications. However, feel free to explore other indices as well, especially those offered in the effectsize package as well. # After parametric test d &lt;- comp %&gt;% cohens_d(freedom_of_choice ~ gender, var.equal = TRUE, ci = TRUE) effectsize::interpret_d(d$effsize) ## [1] &quot;small&quot; ## (Rules: cohen1988) # After non-parametric test wr &lt;- comp %&gt;% wilcox_effsize(freedom_of_choice ~ gender, ci = TRUE) effectsize::interpret_r(wr$effsize) ## [1] &quot;small&quot; ## (Rules: funder2019) Looking at our test results, the female Egyptians perceive freedom_of_choice differently from their male counterparts. This is in line with our boxplots. However, the effect sizes tend to be small, which means the differences between the two groups is marginal. Similar to correlations, group comparisons need to be analysed in two stages, answering two questions: Is the difference between groups significant? If it is significant, is the difference small, medium or large? The combination of both analytical steps gives us a comprehensive answer to our research question and enables us to derive with meaningful conclusions. This applies to all group comparisons covered in this book. 12.2.2 Two Paired groups Sometimes, we are not interested in the difference between subjects, but within them, i.e. we want to know whether the same person provides similar or different responses at two different times. Thus, it becomes evident that observations need to be somehow linked to each other. Paired groups are often found and used in longitudinal studies and in experimental studies (e.g. pre-test vs post-test). For example, if we look at our imdb_top_250 dataset we can see that some directors have more than one movie in the top 250. Therefore, we could be curious to know whether earlier movies of directors have been significantly more successful than their later ones. imdb_top_250 %&gt;% group_by(director) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) ## # A tibble: 155 × 2 ## director n ## &lt;fct&gt; &lt;int&gt; ## 1 Christopher Nolan 7 ## 2 Martin Scorsese 7 ## 3 Stanley Kubrick 7 ## 4 Akira Kurosawa 6 ## 5 Alfred Hitchcock 6 ## 6 Steven Spielberg 6 ## 7 Billy Wilder 5 ## 8 Charles Chaplin 5 ## 9 Hayao Miyazaki 5 ## 10 Ingmar Bergman 5 ## # … with 145 more rows For this investigation we use the modified dataset dir_mov which only contains movies of directors who have two or more movies listed in the IMDb Top 250s. Where directors had more than two movies, I randomly sampled two movies. Thus, there is a certain limitation to our dataset. We can use boxplots to compare earlier movies (i.e. 1) with later movies (i.e. 2) across all directors. Thus, each director is reflected in both groups with one of their movies and therefore the same directors can be found in each group. As a measure of success we use the imdb_rating. dir_mov %&gt;% ggplot(aes(x = movie, y = imdb_rating, fill = movie)) + geom_boxplot() The boxplots look almost identical which suggests that the rating of movies in both groups has not changed significantly. However, the boxplot can only show a summary statistics for each group. Thus, it only implies that the movies in group 1 have about the same ratings as the movies in group 2. If we want to visualise how the ratings have changed for each director from the first to the second movie, we can create a point plot and draw lines with geom_line() to connect the movies in each group. A line that movies up indicates that the second movie was rated higher than the first one and vice versa. dir_mov %&gt;% ggplot(aes(x = movie, y = imdb_rating, colour = director)) + geom_point() + geom_line(aes(group = director)) + # Remove the legend theme(legend.position = &quot;none&quot;) Based on this plot we have to revise our interpretation slightly. Directors who received particularly high ratings on their first movie (i.e. the top 3 in group 1) scored much lower on the second movie. First, we can notice from our boxplots that these movies count as outliers, and second, obtaining such high scores on a movie is tough to replicate. Needless to say, all these movies are rated as very good, otherwise they would not be in this list. It is worth noting that the way the y axis is scaled emphasises differences. Thus, a difference between a rating of 9 and 8.5 appears large. If we change the range of the y axis to ‘0-10,’ the differences appear marginal, but it reflects (1) the possible length of the scale (IMDb ratings range from 0-10) and (2) the magnitude in change relative to the entire scale. More often than note, this ‘zoom-in’ effect is sometimes used to create the illusion of large differences were there are none. Be aware when you present your findings not to create visualisations that could be misleading. dir_mov %&gt;% ggplot(aes(x = movie, y = imdb_rating, colour = director)) + geom_point() + geom_line(aes(group = director)) + # Remove the legend theme(legend.position = &quot;none&quot;)+ # Manuall define the y axis range ylim(0,10) Considering the revised plot, we likely can predict what the statistical test will show. Table 12.2 summarises which tests and functions need to be performed if our data is parametric or non-parametric. In both cases, the functions are the same to those of the unpaired group comparisons, but we need to add the attribute paired = TRUE. Still, the interpretations between the unpaired and paired tests remain the same. Also, be aware that some tests have changed in name, e.g. the Mann-Whitney U test has become the Wilcoxon Signed Rank Test. even though we use the same functions as before, by changing the attributed of paired we also change the computational technique to obtain the results. Thus, be aware that the same function can perform different computations. Table 12.2: Comparing two unpaired groups (effect size functions from package effectsize, except for wilcoxonPairedR() from rcompanion) Assumption Test Function Effect size Function Parametric T-Test t_test(paired = TRUE) Cohen’s d cohens_d() Non-parametric Wilcoxon Signed Rank Test wilcox_test(paired = TRUE) Wilcoxon r wilcoxonPairedR() Let’s apply the functions to find out whether the differences we can see in our plots matter. # Paired T-Test dir_mov %&gt;% t_test(imdb_rating ~ movie, paired = TRUE, var.equal = TRUE, detailed = TRUE) %&gt;% glimpse() ## Rows: 1 ## Columns: 13 ## $ estimate &lt;dbl&gt; 0.04186047 ## $ .y. &lt;chr&gt; &quot;imdb_rating&quot; ## $ group1 &lt;chr&gt; &quot;1&quot; ## $ group2 &lt;chr&gt; &quot;2&quot; ## $ n1 &lt;int&gt; 43 ## $ n2 &lt;int&gt; 43 ## $ statistic &lt;dbl&gt; 0.8717132 ## $ p &lt;dbl&gt; 0.388 ## $ df &lt;dbl&gt; 42 ## $ conf.low &lt;dbl&gt; -0.05504967 ## $ conf.high &lt;dbl&gt; 0.1387706 ## $ method &lt;chr&gt; &quot;T-test&quot; ## $ alternative &lt;chr&gt; &quot;two.sided&quot; ## Wilcoxon Signed Rank Test dir_mov %&gt;% wilcox_test(imdb_rating ~ movie, paired = TRUE) ## # A tibble: 1 × 7 ## .y. group1 group2 n1 n2 statistic p ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 imdb_rating 1 2 43 43 278 0.562 As expected, the paired tests reveal that the differences in rating between the first movie and the second movie are not significant. Usually, there would be no reason to follow this up with the computation of effect sizes because we only need to do this if the differences are statistically significant. However, nothing can stop us from doing so (for demonstration purposes). ## After T-Test d &lt;- cohens_d(imdb_rating ~ movie, data = dir_mov, paired = TRUE, var.equal = TRUE) effectsize::interpret_d(d$effsize) ## [1] &quot;very small&quot; ## (Rules: cohen1988) # After Wilcoxon Signed Rank Test wr &lt;- dir_mov %&gt;% wilcox_effsize(imdb_rating ~ movie, paired = TRUE, ci = TRUE) effectsize::interpret_r(wr$effsize, rules = &quot;cohen1988&quot;) ## [1] &quot;very small&quot; ## (Rules: cohen1988) As we would expect, the effect sizes are very small, irrespective of whether we treat our data as parametric or non-parametric. After all, being a successful director ranked in the IMDb top 250 seems to imply that other movies are equally successful, but remember the limitations of our dataset before drawing your final conclusions. 12.3 Comparing more than two groups Often we find ourselves in situations where comparing two groups is not enough. Instead, we might be faced with three or more groups fairly quickly. For example, the wvs dataset let’s us look at 48 different countries, all of which we could compare very quickly with just a few lines of code. In the following chapters we look at how we can perform the same type of analysis as before, but with multiple unpaired and paired groups using R. Similarly to the two-samples group comparison, we cover the parametric and non-parametric approaches. 12.3.1 Multiple unpaired groups Have you ever been wondering whether people in different countries are equally satisfied with their lives? You might have a rough guess that it is not the case, because the social, economic and political environment might place an import role. If you live in a country that is affected by social conflicts, one’s life satisfaction might be drastically lower. In the following we take a look at three countries Iraq, Japan and Korea. I did not only chose these countries out of personal interest, but because they nicely demonstrate the purpose of the chapter, i.e. finding out whether there are differences in the perception of satisfaction across three countries. At any time, feel free to remove the filter() function to gain the results of all countries in the dataset, but prepare for slightly longer computations. We first create the dataset which only contains the three desired countries. mcomp &lt;- wvs_nona %&gt;% filter(country == &quot;Iraq&quot; | country == &quot;Japan&quot; | country == &quot;Korea&quot;) Similar to before, we can use the ggridges package to draw density plots for each group. This has the added benefit that we can compare the distribution of data for each group and see whether the assumption of normality is likely met or not. On the other hand, we lose the option to easily identify any outliers. You win some and you lose some. mcomp %&gt;% group_by(country) %&gt;% ggplot(aes(x = satisfaction, y = reorder(country, satisfaction), fill = country)) + ggridges::stat_density_ridges(bandwidth = 0.6, quantile_lines = TRUE, # adds median indicator quantiles = (0.5)) + # Remove legend theme(legend.position = &quot;none&quot;) The plot shows us that Japan and Korea appear to be very similar if not identical (based on the median), but Iraq appears to be different from the other two groups. When performing a multiple group comparison we can follow similar steps as before with two groups, i.e. perform the comparison, determine the effect size, and interpret the effect size. Table 12.3 summarises which test needs to be chosen to compare multiple unpaired groups and their corresponding effect size measures. Table 12.3: Comparing multiple unpaired groups (effect size functions from package effectsize) Assumption Test Function for test Effect size Function for effect size1 Parametric ANOVA anova_test (assumes equal variances) oneway.test(var.equal = TRUE/FALSE) Eta squared eta_squared() Non-parametric Kruskall-Wallis test kruskal_test() Epsilon squared (rank) rank_epsilon_squared() Let’s begin by conducting the group comparison. As you will notice, rstatix currently does not support a parametric test where var.equal = FALSE. Therefore we need to fall back to the underlying function oneway.test(var.equal = FALSE) # ANOVA ## equal variances assumed mcomp %&gt;% anova_test(satisfaction ~ country, detailed = TRUE) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 country 4258.329 11314.68 2 3795 714.133 5.74e-264 * 0.273 ## Equal variances not assumed (test &lt;- oneway.test(satisfaction ~ country, data = mcomp, var.equal = FALSE)) ## ## One-way analysis of means (not assuming equal variances) ## ## data: satisfaction and country ## F = 663.17, num df = 2.0, denom df = 2422.8, p-value &lt; 2.2e-16 # Kruskall-Wallis test ## Perform comparison (test &lt;- mcomp %&gt;% kruskal_test(satisfaction ~ country)) ## # A tibble: 1 × 6 ## .y. n statistic df p method ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 satisfaction 3798 1064. 2 1.11e-231 Kruskal-Wallis While anova_test() does provide the effect size automatically, i.e. generalised eta squared (ges), this is not the case for the other two approaches. Therefore, we have to use the effectsize package to help us out. Packages often can get you a long way and make your life easier, but it is good to know alternatives in case a single package does not give you what you need. # # After ANOVA with var.equal = FALSE # effectsize::eta_squared(test) # # # effect size rank epsilon squared # effectsize::rank_epsilon_squared(mcomp$satisfaction ~ mcomp$gender) # # # effect size eta squared (an alternative to epsilon squared) # mcomp %&gt;% kruskal_effsize(satisfaction ~ country) The results show that there is a significant and large difference between these groups. You might argue that this is actually not quite true. Considering our plot, we know that Japan and Korea do not look like as if they are significantly different. Multiple group comparisons only consider differences across all three groups. Therefore, if one group lies far away from the other groups, the test will turn significant and even provide a large enough effect size to consider it important. However, these tests do not provide information which differences between groups are significant. To gain more clarification about this, we need to incorporate another step, so called ‘post-hoc tests.’ These tests compare two groups at a time, which is why they are also known as ‘pairwise comparisons.’ Compared to regular two-sample tests, these perform corrections of the pvalues for mulitple testing, which is necessary. However, there are many different ‘post-hoc’ tests one can choose from. Field (2013) (p.459) nicely outlines the different scenarios and provides recommends to navigate this slightly complex field of post-hoc tests to follow-up a one-way ANOVA. Table 12.4 provides an overview of his suggestions. Table 12.4: Different post-hoc tests for different scenarios (parametric) Equal sample size Equal variances Post-hot tests Functions in R YES YES REGWQ, Tukey, Bonferroni mutoss::regwq()2 rstatix::tukey_hsd() pairwise.t.test(p.adjust.method = \"bonferroni\") NO (slightly different) YES Gabriel YES YES Hochberg’s GT2 Not available in R and should not be confused with pairwise.t.test(p.adjust.method = \"hochberg\"), which is based on Hochberg (1988). The GT2, however, is based on Hochberg (1974). NO (not ideal for small samples) NO Games-Howell rstatix::games_howell_test() You might be surprised to see that there are also post-hoc tests for parametric group comparisons when the assumption of equal variances is not assumed. Would we not have to use a non-parametric test for our group comparison instead? Well, empirical studies have demonstrated that ANOVAs tend to produce robust results, even if the assumption of normality (e.g. Blanca Mena et al. (2017)) is not given, or there is some degree of heterogeneity of variance between groups (Tomarken and Serlin 1986). In other words, there can be some leniancy (or flexibility?) when it comes to the violation of parametric assumptions. If you want to reside on the save side, you should ensure you know your data and its properties. If in doubt, non-parametric tests are also available. If we want to follow up the Kruskall-Wallis test, i.e. the non-parametric equivalent to the one-way ANOVA, we can make use of two post-hoc tests: Dunn Test: rstatix::dunn_test() (Dinno 2015) Pairwise comparison with Bonferroni (and other) correction: pairwise.wilcox.test(). Below are some examples of how you would use these functions in your project. However, be aware that some of the post-hoc tests are not or not well implemented yet in R. Here I show the most important ones which likely serve you in 90% of the cases. # POST_HOC TEST FOR PARAMETRIC DATA # Bonferroni pairwise.t.test(mcomp$satisfaction, mcomp$country, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: mcomp$satisfaction and mcomp$country ## ## Iraq Japan ## Japan &lt;2e-16 - ## Korea &lt;2e-16 1 ## ## P value adjustment method: bonferroni # Tukey mcomp %&gt;% tukey_hsd(satisfaction ~ country) ## # A tibble: 3 × 9 ## term group1 group2 null.value estimate conf.low conf.high p.adj ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 country Iraq Japan 0 2.29 2.13 2.45 0.0000000141 ## 2 country Iraq Korea 0 2.26 2.10 2.43 0.0000000141 ## 3 country Japan Korea 0 -0.0299 -0.189 0.129 0.898 ## # … with 1 more variable: p.adj.signif &lt;chr&gt; # Games-Howell mcomp %&gt;% games_howell_test(satisfaction ~ country) ## # A tibble: 3 × 8 ## .y. group1 group2 estimate conf.low conf.high p.adj p.adj.signif ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 satisfaction Iraq Japan 2.29 2.11 2.47 0 **** ## 2 satisfaction Iraq Korea 2.26 2.11 2.42 5.92e-11 **** ## 3 satisfaction Japan Korea -0.0299 -0.178 0.118 8.84e- 1 ns # POST-HOC TEST FOR NON-PARAMETRIC DATA mcomp %&gt;% dunn_test(satisfaction ~ country) ## # A tibble: 3 × 9 ## .y. group1 group2 n1 n2 statistic p p.adj p.adj.signif ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 satisfaction Iraq Japan 1200 1353 29.2 4.16e-187 1.25e-186 **** ## 2 satisfaction Iraq Korea 1200 1245 27.6 8.30e-168 1.66e-167 **** ## 3 satisfaction Japan Korea 1353 1245 -1.02 3.10e- 1 3.10e- 1 ns # or pairwise.wilcox.test(mcomp$satisfaction, mcomp$country, p.adjust.method = &quot;holm&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: mcomp$satisfaction and mcomp$country ## ## Iraq Japan ## Japan &lt; 2e-16 - ## Korea &lt; 2e-16 0.00093 ## ## P value adjustment method: holm As we can see, no matter which function we use, the interpretation of the results remain the same on this occasion. 12.3.2 Multiple paired groups Additional condition if you compare three or more groups with each other. Might not be good to call them groups actually, because it refers to different measures by the same person usually over an extended period of time. Is an extension of the linear model - so why not simply use a regression instead. Is it because regression primarily use quantitative data and not categorical type data? repeated measures ANOVA (find dataset) # anova_test() # # eta_squared() # omega_squared() Friedman Test (find dataset) # # NON=PARAMETRIC COMPARISON # friedman_test() # # # Effect size # kendalls_w() A useful overview of all the possible options of comparing groups and how to obtain their effect sizes can also be found here https://indrajeetpatil.github.io/statsExpressions/articles/stats_details.html 12.4 Comparing groups based on factors: Contingency tables So far, our dependent variable was always a numeric one. However, what if both, independent and dependent variable, are categorical? In such cases, we can only count the number of occurrences for each combination of the categories. For example, we might recode our variable satisfaction into a dichotomous variable, i.e. participants are either happy or not. Since the original scale ranges from 1-10, we assume that participants who scored higher than 5 are satisfied with their life, while those who scored lower are categorised as unsatisfied. # Create a dichotomous/binary variable for satisfaction wvs_nona &lt;- wvs_nona %&gt;% mutate(satisfaction_bin = as_factor(ifelse(satisfaction &gt;= 5, &quot;satisfied&quot;, &quot;unsatisfied&quot;)) ) Your first intuition is likely to ask: Are there more satisfied or unsatisfied people in my sample? wvs_nona %&gt;% count(satisfaction_bin) ## # A tibble: 2 × 2 ## satisfaction_bin n ## &lt;fct&gt; &lt;int&gt; ## 1 satisfied 61069 ## 2 unsatisfied 8509 The results reveal that there are considerably more people who are satisfied with their life than there are unsatisfied people. In the spirit of group comparisons, we might wonder whether gender differences might exist among the satisfied and unsatisfied group of people. Thus, we want to split the satisfied and unsatisfied responses into male and female groups. We can do this by adding a second argument to the function count(). wvs_nona %&gt;% count(satisfaction_bin, gender) ## # A tibble: 4 × 3 ## satisfaction_bin gender n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 satisfied female 32106 ## 2 satisfied male 28963 ## 3 unsatisfied female 4404 ## 4 unsatisfied male 4105 This tibble reveals that there are more female participants who are satisfied than male ones. However, the same is true for the category unsatisfied. Using absolute values is not very meaningful when the sample size of each group is not equal. Thus, it is better to use the relative frequency instead which we can add as a new variable. ct &lt;- wvs_nona %&gt;% count(satisfaction_bin, gender) %&gt;% group_by(gender) %&gt;% mutate(perc = round(n/sum(n), 3)) ct ## # A tibble: 4 × 4 ## # Groups: gender [2] ## satisfaction_bin gender n perc ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 satisfied female 32106 0.879 ## 2 satisfied male 28963 0.876 ## 3 unsatisfied female 4404 0.121 ## 4 unsatisfied male 4105 0.124 The relative frequency (perc) reveals that female and male participants are equally satisfied and unsatisfied. In other words, we could argue that gender does not predict satisfaction with life, because the proportion of male and female participants is almost identical. A more common and compact way to show such dependencies between categorical variables is a contingency table. To convert our current table into a contingency table we need to map the levels of satisfaction_bin as rows (i.e. satisfied and unsatisfied), and for gender we want each level represented as a column (i.e. male and female). This can be achieved with the function pivot_wider(). It turns our ‘long’ data frame into a ‘wide’ one. Let’s take a look at the output, which is much easier to understand. ct %&gt;% pivot_wider(id_cols = satisfaction_bin, names_from = gender, values_from = perc) ## # A tibble: 2 × 3 ## satisfaction_bin female male ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 satisfied 0.879 0.876 ## 2 unsatisfied 0.121 0.124 The resulting tibble looks like a table as we know it from Excel. It is much more compact than the long format. However, what are the different arguments I passed to the function pivot_wider()? Here is a more detailed explanation of what we just did: id_cols refers to one or more columns which define the groups for each row. In our case, we wanted to group observations based on whether these reflect the state of satisfied or unsatisfied. Thus, each group is only represented once in this column. It underlying concept is comparable to using the function group_by() together with summarise(). names_from defines which variable should be translated into separate columns. In other words, we replace the column gender and create a new column for each level of the factor, i.e. male and female. values_from requires us to specify which variable holds the values that should be entered into our table. Since we want only our percentages included in the final output, we used perc. It is essential to note that we did not change any values but rearranged them. However, it is true that we lost one variable, i.e. n. Where has it gone? When using pivot_wider() we have to make sure we include all variables of interest. By default, the function will drop any other variables not mentioned. If we wanted to keep n, we can include it as another variable which is added to values_from. ct %&gt;% pivot_wider(id_cols = satisfaction_bin, names_from = gender, values_from = c(perc, n)) ## # A tibble: 2 × 5 ## satisfaction_bin perc_female perc_male n_female n_male ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 satisfied 0.879 0.876 32106 28963 ## 2 unsatisfied 0.121 0.124 4404 4105 The table has become even wider, because we have two more columns to show the absolute frequency per gender and satisfaction_bin. As you probably expect, there are also situations where we want to turn a ‘wide’ data frame into a long one. An example with in-depth explanations is shown in Chapter 14.2.1.5. Contingency tables are like plots: They provide an excellent overview of the structure of our data and relationships between variables. However, they provide no certainty about the strength of relationships. Therefore, we need to draw on a set of statistical tests to gain further insights. Similar to previous group comparisons, we can distinguish between paired and unpaired groups. I will cover each comparison in turn and also allude to ways of plotting two more categories in a ggplot(). 12.4.1 Unpaired groups of categorical variables In the introduction to this chapter we covered a classic example of an unpaired comparison of two groups (male and female) regarding another categorical variable, i.e. satisfaction_bin. The tables we produced offered detailed insights into the distribution of these categories. However, it is always helpful to also have a visual representation. To plot two categorical variables (i.e. factors) in ggplot2 can be achieved in many different ways. Three commonly used options are shown in Figure 12.1. # Plot with absolute frequencies (stacked) absolute_stacked &lt;- wvs_nona %&gt;% ggplot(aes(x = satisfaction_bin, fill = gender)) + geom_bar() + ggtitle(&quot;Stacked absolute frequency&quot;) + theme(legend.position = &quot;none&quot;) # Plot with absolute frequencies (grouped) absolute_grouped &lt;- wvs_nona %&gt;% ggplot(aes(x = satisfaction_bin, fill = gender)) + geom_bar(position = &quot;dodge&quot;) + ggtitle(&quot;Grouped absolute frequency&quot;) + theme(legend.position = &quot;none&quot;) # Plot with relative frequencies relative &lt;- wvs_nona %&gt;% ggplot(aes(x = satisfaction_bin, fill = gender)) + geom_bar(position = &quot;fill&quot;) + ggtitle(&quot;Relative frequency&quot;) + theme(legend.position = &quot;none&quot;) # Plot all three plots with &#39;patchwork&#39; absolute_stacked + absolute_grouped + relative + plot_spacer() Figure 12.1: Three ways to plot frequencies A more elegant and compact way of visualising frequencies across two or more categories are mosaic plots. These visualise relative frequencies for both variables in one plot. Consider the following mosaic plot created with ggmosaic and the function geom_mosaic(). library(ggmosaic) wvs_nona %&gt;% ggplot() + geom_mosaic(aes(x = product(satisfaction_bin, gender), fill = gender)) + theme_mosaic() Figure 12.2: A mosaic plot visualising the relationship of two categorical variables From our data it might not be obvious, but the height and the width of the bars is determine by frequencies of each variable. In other words, the width of the bars (i.e. x-axis) is determine by the relative frequency of female and male participants in our sample. On the other hand, the height of each bar (i.e. the y-axis) is determine by the relative frequency of satisfied and `unsatisfied. This results square block that is divided by the respective relative distributions. Let me share an example where it is more apparent what a mosaic plot aims to achieve. In this example we can tell that there were more male participants than females because the bar for male is much wider. Apart from that we can notice that female participants have more missing values NA for the variable married. However, more female participants reported that they are married, i.e. answered with yes. While mosaic plots make for impressive visualisations, we have to be mindful that more complex visualisations are always more challenging to understand. Thus, it is wise to carefully plan the usage of such plots. Throughout the remaining chapters I will use the mosaic plot to illustrate distributions. A main difference to regular bar plots is the function product(), which allows us to define different variables of interest instead of using x and y in the aes() of ggplot(). Apart from that, the same ggplot syntax applies. When it comes to the computational side of things, we have to distinguish whether our two variables create a 2-by-2 matrix, i.e. both variables only have two levels, or whether our two variables have multiple levels. Depending on which scenario applies to our analysis, a different statistical test has to be performed. For some tests, a minimum frequency for each value in our contingency table (i.e. cell) needs to be achieved. This is usually a matter of sample size and diversity in a sample. Table 12.5 provides an overview of the different scenarios and indicates the functions we have to use to conduct our analysis in R. Table 12.5: Statistical tests to compare two unpaired categorical variables. Effect sizes are computed using the effectsize package. Matrix Condition Test Function in R Effect size 2x2 &lt; 10 obs. Fisher’s Exact Test fisher.test() phi() 2x2 &gt; 10 obs. Chi-squared Test with Yate’s Continuity Correction infer::chisq_test(correct = TRUE)3 cramers_v() n x n &gt; 5 (80% of cells) Chi-squared Test infer::chisq_test() cramers_v() To cut a long story short, we only need to be worried about 2x2 contingency tables where the values in some (or all) cells is lower than 10. In those cases we need to rely on the Fisher’s Exact Test. In all other cases we can rely on the Pearson Chi-squared Test to do our bidding. The function infer::chisq_test() is based on the function chisq.test(), which automatically applies the required Yate’s Continuity Correction if necessary. Every test that involves two categorical variables we have to perform three steps: Compute a contingency table and check the conditions outlined in Table 12.5. Conduct the appropriate statistical test. If the test is significant, compute the effect size and interpret its value. Considering our example from the beginning of the chapter, we are confronted with a 2x2 table which has the following distribution: ct %&gt;% pivot_wider(id_cols = satisfaction_bin, names_from = gender, values_from = n) ## # A tibble: 2 × 3 ## satisfaction_bin female male ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; ## 1 satisfied 32106 28963 ## 2 unsatisfied 4404 4105 We easily satisfy the requirement for a regular Chi-squared test with Yate’s continuity correction, because each row has at least a value of 10. However, for demonstration purposes I will show how to compute both, the Chi-squared test and the Fisher’s Exact test for the same contingency table. # Fisher&#39;s Exact Test fisher.test(wvs_nona$satisfaction_bin, wvs_nona$gender) %&gt;% # Make output more readable broom::tidy() %&gt;% glimpse() ## Rows: 1 ## Columns: 6 ## $ estimate &lt;dbl&gt; 1.033269 ## $ p.value &lt;dbl&gt; 0.1609549 ## $ conf.low &lt;dbl&gt; 0.9871339 ## $ conf.high &lt;dbl&gt; 1.081518 ## $ method &lt;chr&gt; &quot;Fisher&#39;s Exact Test for Count Data&quot; ## $ alternative &lt;chr&gt; &quot;two.sided&quot; ## Effect size (phi &lt;- effectsize::phi(wvs_nona$satisfaction_bin, wvs_nona$gender)) ## Phi | 95% CI ## ----------------------- ## 5.36e-03 | [0.00, 0.01] effectsize::interpret_r(phi$phi, rules = &quot;cohen1988&quot;) ## [1] &quot;very small&quot; ## (Rules: cohen1988) # Chi-squared test with Yate&#39;s continuity correction wvs_nona %&gt;% infer::chisq_test(satisfaction_bin ~ gender, correct = TRUE) ## # A tibble: 1 × 3 ## statistic chisq_df p_value ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1.96 1 0.161 ## Effect size cv &lt;- effectsize::cramers_v(wvs_nona$satisfaction_bin, wvs_nona$gender) effectsize::interpret_r(cv$Cramers_v, rules = &quot;cohen1988&quot;) ## [1] &quot;very small&quot; ## (Rules: cohen1988) Both tests reveal that the relationship between our variables is not significant and the effect sizes are very small. This result is very much line with our visualisation shown in Figure 12.2 Contingency tables do not always come as 2x2 matrices. Therefore, it makes sense to look at one more example where we have a much larger matrix. Bear in mind that the larger your matrix, the larger your dataset has to be to produce reliable results. A common question during other matrix - Chi-squared test # Check whether we fulfill the criteria wvs_nona %&gt;% count(relationship_status, gender) %&gt;% group_by(gender) %&gt;% mutate(perc = round(n/sum(n), 3)) %&gt;% pivot_wider(id_cols = relationship_status, names_from = gender, values_from = perc) ## # A tibble: 6 × 3 ## relationship_status female male ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 married 0.571 0.588 ## 2 living together as married 0.069 0.065 ## 3 separated 0.026 0.019 ## 4 widowed 0.084 0.025 ## 5 single 0.202 0.274 ## 6 divorced 0.048 0.03 wvs_nona %&gt;% infer::chisq_test(relationship_status ~ gender) ## # A tibble: 1 × 3 ## statistic chisq_df p_value ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1669. 5 0 # effectsize::cramers_v() 12.4.2 Paired groups of categorical variables # mcnemar.test() # # # Effect size # cohens_g() 12.5 A cheatsheet to guide your own group comparisons To summarise what we have covered in this section, we can consider References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
