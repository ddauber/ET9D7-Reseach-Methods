# Comparing groups

```{r echo=FALSE}
library(tidyverse)
library(r4np)
library(broom)
library(effectsize)

wvs_nona <- read_csv("wvs_nona.csv")
```

Social Sciences is about the study of human beings and their interactions. As such, we frequently want to compare two or more groups of human beings, organisations, teams, countries, etc., with each other to see whether they are similar or different from each other. Sometimes we also want to track individuals over time and see how they may have changed in some way or other. In short, comparing groups is an essential technique to make inferences and helps us better understand the diversity that surrounds us.

If we want to perform a group comparison we have to consider which technique is most appropriate for the data we have. Some of it might be related to the type of data we have collected, other aspects might be linked to the distribution of the data. More specifically, before we apply any statistical technique we have to consider at least the following:

-   missing data (see Chapter \@ref(dealing-with-missing-data)),

-   outliers (see Chapter \@ref(dealing-with-outliers), and

-   the assumptions made by analytical techniques about our data

While we covered missing data and outliers in previous chapters, we have yet to discuss assumptions. For group comparisons there are three questions we need to answer:

-   Is my data parametric or non-parametric? (see Chapter \@ref(parametric-or-non-parametric))

-   How many groups do I wish to compare?

-   Are these groups paired or unpaired?

In the following we will look at group comparisons for parametric and non-parametric data in each category and use the `wvs_nona` dataset, i.e. the `wvs` dataframe after we performed imputation (see also Chapter \@ref(replacing-removing-missing-data)). Since we already covered how to test whether data is parametric or non-parametric we will forgo this step out of pure convenience and to remain succinct. We also ignore any potential outliers or missing data. The case studies at the end of the book provide realistic examples of how to perform groups comparisons with a new set of data (see Chapter \@ref()). Thus, parametric and non-parametric tests will be demonstrated with the same dataset and the same variables.

## Comparing two groups {#comparing-two-groups}

The simplest of comparisons is the one where you only have two groups. In our case, we are interested in whether participants perceive `freedom_of_choice` in the same way across different genders and across different countries.

### Two Unpaired groups {#two-unpaired-groups}

An unpaired group test assumes that the observations in each group are not related to each other, for example that the participants in each group are different individuals.

Our first comparison will be participants from `Egypt` and we want to understand whether male and female citizens in this country perceive that they have `freedom_of_choice`.

We first can compare these two groups using our trusty `geom_boxplot` (or any variation of it).

```{r Two unpaired groups visualisation, echo=TRUE}
# Only select participants from 'Egypt'
comp <- wvs_nona %>%
  filter(country == "Egypt")

# Compute the mean for each group
group_means <- comp %>% 
  group_by(gender) %>% 
  summarise(g_mean = mean(freedom_of_choice))

# Create our data visualisation
comp %>% 
  ggplot(aes(x = gender, y = freedom_of_choice, fill = gender)) +
  geom_boxplot() +
  
  # Add the mean for each group
  geom_point(data = group_means,
             aes(x = gender, y = g_mean),
             shape = 3,
             size = 2
             )
```

While the distribution looks similar, we can notice that the median and the mean (marked by the cross inside the boxplot) are slighter higher for `male` participants. Thus, we could can suspect slight differences between these two groups, but we do not know whether these differences are significant or not. To consider the significance (remember Chapter \@ref(significance)) and the effect size (see Table \@ref(tab:effect-size-cohen)) we have to perform statistical tests.

Table \@ref(tab:comparing-two-groups-unpaired) summarises the different tests and functions to perform the group comparison computationally. It is important to note that the parametric test compares the means of two groups, while the non-parametric test compares ranks, especially the median. All tests turn significant if the differences between groups is large enough. Thus, significant results can be read as 'these groups are significantly different from each other'. Of course, if the difference is not significant, the groups are considered to be not different from each other.

| Assumption     | Test           | Function for test | Effect size     | Function for effect size |
|----------------|----------------|-------------------|-----------------|--------------------------|
| Parametric     | T-Test         | `t.test()`        | Cohen's d       | `cohens_d()`             |
| Non-parametric | Mann-Whitney U | `wilcox.test()`   | Rank biserial r | `rank_biserial()`        |

: (\#tab:comparing-two-groups-unpaired) Comparing two unpaired groups (effect size functions from package `effectsize`

```{r Two unpaired groups computation, echo=TRUE}
# PARAMETRIC COMPARISON
## Perform the comparison
(gcomp <- t.test(freedom_of_choice ~ gender, data = comp))

## Determine the effect size
(d <- cohens_d(freedom_of_choice ~ gender, data = comp))

## Interpret the effect size
interpret_d(d$Cohens_d)

# NON-PARAMETRIC COMPARISON
## Perform the comparison
(gcomp <- wilcox.test(freedom_of_choice ~ gender, data = comp))

## Determine the effect size via rank biserial correlation
(d <- rank_biserial(freedom_of_choice ~ gender, data = comp))

## Interpret the effect size
interpret_rank_biserial(d$r_rank_biserial, rules = "cohen1988")
```

### Two Paired groups {#two-paired-groups}

Paired sample test:

-   use in longitudinal studies

-   used in experimental studies (pre-test vs post-test)

We want to know whether their earlier movies have been significantly more successful than others. We use the data frame `dir_mov` which only contains movies of directors who have two or more movies listen in the IMDb Top 250s.

```{r Comparing two paired groups data visualisation boxplot, echo=TRUE}
dir_mov %>% 
  ggplot(aes(x = movie, y = imdb_rating, fill = movie)) +
  geom_boxplot()
```

The boxplots look almost identical which suggests that the rating of movies in both groups has not changed significantly. However, the boxplot can only show a summary statistics for each group. Thus, it only implies that the movies in group `1` have about the same rating as the movies in `2`. If we want to visualise how the ratings have changed for each director from the first to the second movie, we can create a point plot and draw lines with `geom_line()` to connect the movies in each group. Line that movies up indicates that the second movie was rated higher than the first one and vice versa.

```{r Comparing two paired groups data visualisation line plot, echo=TRUE}
dir_mov %>%
  ggplot(aes(x = movie, y = imdb_rating, colour = director)) +
  geom_point() +
  geom_line(aes(group = director)) +
  # Remove the legend
  theme(legend.position = "none")
```

Based on this plot we have to revise our interpretation slightly. Directors who received particularly high ratings on their first movie (i.e. the top 3) scored much lower on the second movie. For once, we noticed from our boxplots that these movies count as outliers, and second, obtaining such high scores on a movie is tough to replicate. Needless to say, all these movies are rated as very good, otherwise they would not be in this list. It is worth noting that the way the y axis is scaled emphasises differences. Thus, a difference between a rating of 9 and 8.5 appears large. If we change the range of the y axis to '0-10', the differences appear marginal, but it reflects (1) the possible length of the scale (IMDb ratings range from 0-10) and (2) the magnitude in change relative to the entire scale.

```{r Comparing two paired groups data visualisation line plot and full y scale, echo=TRUE}
dir_mov %>%
  ggplot(aes(x = movie, y = imdb_rating, colour = director)) +
  geom_point() +
  geom_line(aes(group = director)) +
  # Remove the legend
  theme(legend.position = "none")+
  # Manuall define the y axis range
  ylim(0,10)
```

Considering this last plot, we likely can predict what the statistical test will show. Table \@ref(tab:comparing-two-groups-paired) summarises which tests and functions need to be performed if our data is parametric or non-parametric. In both cases, the functions are the same, but we need to add the attribute `paired = TRUE`. The interpretations between the unpaired and paired tests remain the same.

| Assumption     | Test                      | Function for test            | Effect size     | Function for effect size |
|----------------|---------------------------|------------------------------|-----------------|--------------------------|
| Parametric     | T-Test                    | `t.test(paired = TRUE)`      | Cohen's d       | `cohens_d()`             |
| Non-parametric | Wilcoxon Signed Rank Test | `wilcox.test(paired = TRUE)` | Rank biserial r | `rank_biserial()`        |

: (\#tab:comparing-two-groups-paired) Comparing two unpaired groups (effect size functions from package `effectsize`

```{r Comparing two paired groups data computation, echo=TRUE, warning=FALSE}

# PARAMETRIC COMPARISON
## Perform the comparison
(gcomp <- t.test(imdb_rating ~ movie, data = dir_mov, paired = TRUE))

## Determine the effect size
(d <- cohens_d(imdb_rating ~ movie, data = dir_mov))

## Interpret the effect size
interpret_d(d$Cohens_d)

# NON-PARAMETRIC COMPARISON
## Perform the comparison
(gcomp <- wilcox.test(imdb_rating ~ movie, data = dir_mov, paired = TRUE))

## Determine the effect size via rank biserial correlation
(d <- rank_biserial(imdb_rating ~ movie, data = dir_mov))

## Interpret the effect size
interpret_rank_biserial(d$r_rank_biserial, rules = "cohen1988")
```

As expected, the paired tests reveal that the differences in rating between the first movie and the second movie are not significant and the effect sizes are very small, irrespective of whether we treat our data as parametric or non-parametric.

## Comparing more than two groups {#comparing-more-than-two-groups}

### Multiple unpaired groups {#multiple-unpaired-groups}

While we could plot boxplots again, let me share with you another approach, based on density plots. This has the added benefit that we can compare the distribution of data for each group and see whether the assumption of normality is likely met or not. On the other hand, we lose the option to identify any outliers.

```{r Multiple unpaired groups data visualisation, echo=TRUE}
wvs_nona %>% 
  filter(country == "Iraq" | country == "Puerto Rico" | country == "Japan") %>%
  ggplot(aes(x = satisfaction, y = country, fill = country)) +
  ggridges::stat_density_ridges(bandwidth = 0.5,
                                quantile_lines = TRUE,
                                quantiles = (0.5)) +      # adds the median indicator
  # Remove legend
  theme(legend.position = "none")
```

anova()

kruskal.test()

### Multiple paired groups {#multiple-paired-groups}

repeated measures ANOVA

Friedman Test

## Comparing groups based on factors: The Chi-squared test {#chi-squared-test}

## A cheatsheet to guide your own group comparisons {#cheatsheet-group-comparisons}

To summarise what we have covered in this section, we can consider

```{r How to decide on the right group comparison, echo=FALSE}
DiagrammeR::mermaid("
        graph TB

        data(my data)
        datatype{type of data}
        quan[quantitative]
        qual[qualitative]
        paracheck{<center>check for <br> assumptions</center>}
        addlin[additivity and linerarity]
        normal[normality]
        homvar[homogeneity of variance]
        indep[independence]
        para[parametric]
        npara[non-parametric]
        
        data --> datatype
        
        subgraph 
        datatype --> quan
        datatype --> qual
        end
        
        
        quan --> paracheck
        qual --> npara
        
        paracheck --> addlin
        
        subgraph 
        addlin -- yes --> indep
        indep -- yes --> normal
        normal -- yes --> homvar
        end

        addlin -- no --> npara
        indep -- no --> npara
        normal -- no --> npara
        homvar -- no --> npara

        homvar -- yes --> para
        
        # hwg[How many groups?]
        ")


```
